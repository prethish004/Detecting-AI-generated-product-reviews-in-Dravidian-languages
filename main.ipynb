{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Bb_Vj-P7VXT"
      },
      "source": [
        "Tamil use *bert-base-multilingual-cased*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vRgXgZrFSfI3",
        "outputId": "56ad57e1-37ee-4c74-e684-d780c434ae21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: indic-nlp-library in /usr/local/lib/python3.10/dist-packages (0.92)\n",
            "Requirement already satisfied: advertools in /usr/local/lib/python3.10/dist-packages (0.16.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.5.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: sphinx-argparse in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library) (0.5.2)\n",
            "Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library) (3.0.2)\n",
            "Requirement already satisfied: morfessor in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library) (2.0.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library) (2.2.2)\n",
            "Requirement already satisfied: pyasn1>=0.4 in /usr/local/lib/python3.10/dist-packages (from advertools) (0.6.1)\n",
            "Requirement already satisfied: scrapy>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from advertools) (2.12.0)\n",
            "Requirement already satisfied: twython>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from advertools) (3.9.1)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from advertools) (17.0.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: Twisted>=21.7.0 in /usr/local/lib/python3.10/dist-packages (from scrapy>=2.5.0->advertools) (24.11.0)\n",
            "Requirement already satisfied: cryptography>=37.0.0 in /usr/local/lib/python3.10/dist-packages (from scrapy>=2.5.0->advertools) (43.0.3)\n",
            "Requirement already satisfied: cssselect>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from scrapy>=2.5.0->advertools) (1.2.0)\n",
            "Requirement already satisfied: itemloaders>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from scrapy>=2.5.0->advertools) (1.3.2)\n",
            "Requirement already satisfied: parsel>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scrapy>=2.5.0->advertools) (1.9.1)\n",
            "Requirement already satisfied: pyOpenSSL>=22.0.0 in /usr/local/lib/python3.10/dist-packages (from scrapy>=2.5.0->advertools) (24.2.1)\n",
            "Requirement already satisfied: queuelib>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from scrapy>=2.5.0->advertools) (1.7.0)\n",
            "Requirement already satisfied: service-identity>=18.1.0 in /usr/local/lib/python3.10/dist-packages (from scrapy>=2.5.0->advertools) (24.2.0)\n",
            "Requirement already satisfied: w3lib>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from scrapy>=2.5.0->advertools) (2.2.1)\n",
            "Requirement already satisfied: zope.interface>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from scrapy>=2.5.0->advertools) (7.2)\n",
            "Requirement already satisfied: protego>=0.1.15 in /usr/local/lib/python3.10/dist-packages (from scrapy>=2.5.0->advertools) (0.3.1)\n",
            "Requirement already satisfied: itemadapter>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from scrapy>=2.5.0->advertools) (0.10.0)\n",
            "Requirement already satisfied: tldextract in /usr/local/lib/python3.10/dist-packages (from scrapy>=2.5.0->advertools) (5.1.3)\n",
            "Requirement already satisfied: lxml>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from scrapy>=2.5.0->advertools) (5.3.0)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from scrapy>=2.5.0->advertools) (0.7.1)\n",
            "Requirement already satisfied: PyDispatcher>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from scrapy>=2.5.0->advertools) (2.0.7)\n",
            "Requirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from twython>=3.8.0->advertools) (1.3.1)\n",
            "Requirement already satisfied: sphinx>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from sphinx-argparse->indic-nlp-library) (8.1.3)\n",
            "Requirement already satisfied: docutils>=0.19 in /usr/local/lib/python3.10/dist-packages (from sphinx-argparse->indic-nlp-library) (0.21.2)\n",
            "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in /usr/local/lib/python3.10/dist-packages (from sphinx-rtd-theme->indic-nlp-library) (4.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=37.0.0->scrapy>=2.5.0->advertools) (1.17.1)\n",
            "Requirement already satisfied: jmespath>=0.9.5 in /usr/local/lib/python3.10/dist-packages (from itemloaders>=1.0.1->scrapy>=2.5.0->advertools) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.17.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.4.0->twython>=3.8.0->advertools) (3.2.2)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from service-identity>=18.1.0->scrapy>=2.5.0->advertools) (24.3.0)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.10/dist-packages (from service-identity>=18.1.0->scrapy>=2.5.0->advertools) (0.4.1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: Jinja2>=3.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.5)\n",
            "Requirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.18.0)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.16.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
            "Requirement already satisfied: tomli>=2 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.2.1)\n",
            "Requirement already satisfied: automat>=24.8.0 in /usr/local/lib/python3.10/dist-packages (from Twisted>=21.7.0->scrapy>=2.5.0->advertools) (24.8.1)\n",
            "Requirement already satisfied: constantly>=15.1 in /usr/local/lib/python3.10/dist-packages (from Twisted>=21.7.0->scrapy>=2.5.0->advertools) (23.10.4)\n",
            "Requirement already satisfied: hyperlink>=17.1.1 in /usr/local/lib/python3.10/dist-packages (from Twisted>=21.7.0->scrapy>=2.5.0->advertools) (21.0.0)\n",
            "Requirement already satisfied: incremental>=24.7.0 in /usr/local/lib/python3.10/dist-packages (from Twisted>=21.7.0->scrapy>=2.5.0->advertools) (24.7.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zope.interface>=5.1.0->scrapy>=2.5.0->advertools) (75.1.0)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.10/dist-packages (from tldextract->scrapy>=2.5.0->advertools) (2.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=37.0.0->scrapy>=2.5.0->advertools) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.0.2)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"dataset_df\",\n  \"rows\": 808,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 808,\n        \"samples\": [\n          \"TAM_HUAI_TR_698\",\n          \"TAM_HUAI_TR_297\",\n          \"TAM_HUAI_TR_228\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transcript\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 784,\n        \"samples\": [\n          \"\\u0ba4\\u0bc1\\u0ba3\\u0bbf \\u0ba4\\u0bb0\\u0bae\\u0bbe\\u0b95 \\u0b89\\u0bb3\\u0bcd\\u0bb3\\u0ba4\\u0bc1\",\n          \"\\u0ba4\\u0bb0\\u0bae\\u0bbe\\u0ba9 \\u0bae\\u0bbf\\u0ba9\\u0bcd\\u0b95\\u0bb2\\u0bae\\u0bcd.\",\n          \"\\u0b87\\u0ba8\\u0bcd\\u0ba4 \\u0baa\\u0bc7\\u0baa\\u0bbf \\u0bb2\\u0bcb\\u0bb7\\u0ba9\\u0bcd \\u0ba8\\u0bb2\\u0bcd\\u0bb2 \\u0bb5\\u0bbe\\u0b9a\\u0ba9\\u0bc8 \\u0b95\\u0bca\\u0ba3\\u0bcd\\u0b9f\\u0ba4\\u0bc1.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"HUMAN\",\n          \"AI\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_transcript\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 783,\n        \"samples\": [\n          \"\\u0ba4\\u0bc1\\u0ba3\\u0bbf \\u0ba4\\u0bb0\\u0bae\\u0bbe\\u0b95\",\n          \"\\u0ba4\\u0bb0\\u0bae\\u0bbe\\u0ba9 \\u0bae\\u0bbf\\u0ba9\\u0bcd\\u0b95\\u0bb2\\u0bae\\u0bcd .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "dataset_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e0a77855-256c-4464-abd4-c9bc1ed1b12d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>transcript</th>\n",
              "      <th>class_label</th>\n",
              "      <th>cleaned_transcript</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TAM_HUAI_TR_001</td>\n",
              "      <td>இந்த சோப்பின் மணம் மிகவும் புத்துணர்ச்சியூட்டு...</td>\n",
              "      <td>AI</td>\n",
              "      <td>சோப்பின் மணம் புத்துணர்ச்சியூட்டும் வகையில் .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TAM_HUAI_TR_002</td>\n",
              "      <td>தோலை நன்கு சுத்தம் செய்ய இது மிகவும் சிறப்பானது.</td>\n",
              "      <td>AI</td>\n",
              "      <td>தோலை நன்கு சுத்தம் செய்ய சிறப்பானது .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TAM_HUAI_TR_003</td>\n",
              "      <td>இதைப் பயன்படுத்திய பிறகு, தோல் மிக மென்மையாக உ...</td>\n",
              "      <td>AI</td>\n",
              "      <td>இதைப் பயன்படுத்திய , தோல் மென்மையாக .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TAM_HUAI_TR_004</td>\n",
              "      <td>இந்த சோப்பில் இயற்கையான மூலப்பொருட்கள் பயன்படு...</td>\n",
              "      <td>AI</td>\n",
              "      <td>சோப்பில் இயற்கையான மூலப்பொருட்கள் பயன்படுத்தப்...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TAM_HUAI_TR_005</td>\n",
              "      <td>சிறிது சோப்பு போதும், அதிக நுரை உருவாகிறது.</td>\n",
              "      <td>AI</td>\n",
              "      <td>சிறிது சோப்பு போதும் , நுரை உருவாகிறது .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>803</th>\n",
              "      <td>TAM_HUAI_TR_804</td>\n",
              "      <td>இந்த லிப்ஸ்டிக் எனக்கு பேய் மாதிரி இருக்கு</td>\n",
              "      <td>HUMAN</td>\n",
              "      <td>லிப்ஸ்டிக் பேய் மாதிரி இருக்கு</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>804</th>\n",
              "      <td>TAM_HUAI_TR_805</td>\n",
              "      <td>இதே போட்டோ அழகா இருக்கு</td>\n",
              "      <td>HUMAN</td>\n",
              "      <td>இதே போட்டோ அழகா இருக்கு</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>805</th>\n",
              "      <td>TAM_HUAI_TR_806</td>\n",
              "      <td>சோப்பு வாசனை நல்லா இருக்கு</td>\n",
              "      <td>HUMAN</td>\n",
              "      <td>சோப்பு வாசனை நல்லா இருக்கு</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>806</th>\n",
              "      <td>TAM_HUAI_TR_807</td>\n",
              "      <td>எண்ணெய்ன பிசுக்கு போகவே மாட்டேங்குது</td>\n",
              "      <td>HUMAN</td>\n",
              "      <td>எண்ணெய்ன பிசுக்கு போகவே மாட்டேங்குது</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>807</th>\n",
              "      <td>TAM_HUAI_TR_808</td>\n",
              "      <td>தலை எப்பவுமே ஆயில் இருக்கு பிசுபிசுன்னு ஒட்டிக...</td>\n",
              "      <td>HUMAN</td>\n",
              "      <td>தலை எப்பவுமே ஆயில் இருக்கு பிசுபிசுன்னு ஒட்டிக...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>808 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0a77855-256c-4464-abd4-c9bc1ed1b12d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e0a77855-256c-4464-abd4-c9bc1ed1b12d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e0a77855-256c-4464-abd4-c9bc1ed1b12d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-af5786c8-b0a0-4014-8e14-a7dd38b69115\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-af5786c8-b0a0-4014-8e14-a7dd38b69115')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-af5786c8-b0a0-4014-8e14-a7dd38b69115 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e540b668-015f-4878-959a-235f0233a732\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dataset_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e540b668-015f-4878-959a-235f0233a732 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dataset_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                  id                                         transcript  \\\n",
              "0    TAM_HUAI_TR_001  இந்த சோப்பின் மணம் மிகவும் புத்துணர்ச்சியூட்டு...   \n",
              "1    TAM_HUAI_TR_002   தோலை நன்கு சுத்தம் செய்ய இது மிகவும் சிறப்பானது.   \n",
              "2    TAM_HUAI_TR_003  இதைப் பயன்படுத்திய பிறகு, தோல் மிக மென்மையாக உ...   \n",
              "3    TAM_HUAI_TR_004  இந்த சோப்பில் இயற்கையான மூலப்பொருட்கள் பயன்படு...   \n",
              "4    TAM_HUAI_TR_005        சிறிது சோப்பு போதும், அதிக நுரை உருவாகிறது.   \n",
              "..               ...                                                ...   \n",
              "803  TAM_HUAI_TR_804         இந்த லிப்ஸ்டிக் எனக்கு பேய் மாதிரி இருக்கு   \n",
              "804  TAM_HUAI_TR_805                            இதே போட்டோ அழகா இருக்கு   \n",
              "805  TAM_HUAI_TR_806                         சோப்பு வாசனை நல்லா இருக்கு   \n",
              "806  TAM_HUAI_TR_807               எண்ணெய்ன பிசுக்கு போகவே மாட்டேங்குது   \n",
              "807  TAM_HUAI_TR_808  தலை எப்பவுமே ஆயில் இருக்கு பிசுபிசுன்னு ஒட்டிக...   \n",
              "\n",
              "    class_label                                 cleaned_transcript  \n",
              "0            AI      சோப்பின் மணம் புத்துணர்ச்சியூட்டும் வகையில் .  \n",
              "1            AI              தோலை நன்கு சுத்தம் செய்ய சிறப்பானது .  \n",
              "2            AI              இதைப் பயன்படுத்திய , தோல் மென்மையாக .  \n",
              "3            AI  சோப்பில் இயற்கையான மூலப்பொருட்கள் பயன்படுத்தப்...  \n",
              "4            AI           சிறிது சோப்பு போதும் , நுரை உருவாகிறது .  \n",
              "..          ...                                                ...  \n",
              "803       HUMAN                     லிப்ஸ்டிக் பேய் மாதிரி இருக்கு  \n",
              "804       HUMAN                            இதே போட்டோ அழகா இருக்கு  \n",
              "805       HUMAN                         சோப்பு வாசனை நல்லா இருக்கு  \n",
              "806       HUMAN               எண்ணெய்ன பிசுக்கு போகவே மாட்டேங்குது  \n",
              "807       HUMAN  தலை எப்பவுமே ஆயில் இருக்கு பிசுபிசுன்னு ஒட்டிக...  \n",
              "\n",
              "[808 rows x 4 columns]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install transformers indic-nlp-library advertools\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report\n",
        "from indicnlp.tokenize import indic_tokenize\n",
        "from indicnlp.normalize.indic_normalize import IndicNormalizerFactory\n",
        "import advertools as adv\n",
        "import pickle\n",
        "\n",
        "file_path = \"/content/tam_training_data_hum_ai (1).csv\"\n",
        "dataset_df = pd.read_csv(file_path)\n",
        "dataset_df.columns = ['id', 'transcript', 'class_label']\n",
        "dataset_df\n",
        "\n",
        "stopwords = list(sorted(adv.stopwords['tamil']))\n",
        "\n",
        "def preprocess_tamil_text(text):\n",
        "    \"\"\"Preprocess Tamil text by normalizing, tokenizing, and removing stopwords.\"\"\"\n",
        "    normalizer_factory = IndicNormalizerFactory()\n",
        "    normalizer = normalizer_factory.get_normalizer(\"ta\")\n",
        "    text = normalizer.normalize(text)\n",
        "    tokens = list(indic_tokenize.trivial_tokenize(text, lang=\"ta\"))\n",
        "    tokens = [token for token in tokens if token not in stopwords]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "dataset_df['cleaned_transcript'] = dataset_df['transcript'].apply(preprocess_tamil_text)\n",
        "dataset_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRaq8_HWS7U9",
        "outputId": "3ae75878-f940-41d3-c87f-a78e46c0fc56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label encoder saved to tamil_label_encoder.pkl\n"
          ]
        }
      ],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "dataset_df['encoded_label'] = label_encoder.fit_transform(dataset_df['class_label'])\n",
        "\n",
        "label_encoder_path = \"tamil_label_encoder.pkl\"\n",
        "with open(label_encoder_path, \"wb\") as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "\n",
        "print(f\"Label encoder saved to {label_encoder_path}\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    dataset_df['cleaned_transcript'], dataset_df['encoded_label'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "def extract_embeddings(model_name, texts):\n",
        "    \"\"\"Extract embeddings for the given texts using a pre-trained transformer model.\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModel.from_pretrained(model_name).to(device)\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "    batch_size = 16\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(texts), batch_size):\n",
        "            batch_texts = texts[i:i+batch_size]\n",
        "            encoded_inputs = tokenizer(batch_texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "            encoded_inputs = {key: tensor.to(device) for key, tensor in encoded_inputs.items()}\n",
        "            outputs = model(**encoded_inputs)\n",
        "            batch_embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "            embeddings.extend(batch_embeddings)\n",
        "    return np.array(embeddings)\n",
        "\n",
        "X_train_embeddings = extract_embeddings(\"bert-base-multilingual-cased\", X_train.tolist())\n",
        "X_test_embeddings = extract_embeddings(\"bert-base-multilingual-cased\", X_test.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v8EZcC8tTDFb",
        "outputId": "338819dd-4f74-4451-f315-7eec358f4040"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m196,864\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m258\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">231,554</span> (904.51 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m231,554\u001b[0m (904.51 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">230,786</span> (901.51 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m230,786\u001b[0m (901.51 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - accuracy: 0.7039 - loss: 0.7573 - val_accuracy: 0.9691 - val_loss: 0.2501\n",
            "Epoch 2/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9304 - loss: 0.2212 - val_accuracy: 0.9691 - val_loss: 0.1763\n",
            "Epoch 3/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9482 - loss: 0.1389 - val_accuracy: 0.9691 - val_loss: 0.1433\n",
            "Epoch 4/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9702 - loss: 0.1017 - val_accuracy: 0.9568 - val_loss: 0.1634\n",
            "Epoch 5/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9640 - loss: 0.1122 - val_accuracy: 0.8519 - val_loss: 0.3011\n",
            "Epoch 6/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9678 - loss: 0.0769 - val_accuracy: 0.9074 - val_loss: 0.2364\n",
            "Epoch 7/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9572 - loss: 0.1253 - val_accuracy: 0.9568 - val_loss: 0.1661\n",
            "Epoch 8/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9739 - loss: 0.0753 - val_accuracy: 0.9568 - val_loss: 0.1300\n",
            "Epoch 9/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9659 - loss: 0.0970 - val_accuracy: 0.9444 - val_loss: 0.1323\n",
            "Epoch 10/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9518 - loss: 0.1106 - val_accuracy: 0.8951 - val_loss: 0.2087\n",
            "Epoch 11/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9775 - loss: 0.0571 - val_accuracy: 0.9321 - val_loss: 0.1523\n",
            "Epoch 12/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9870 - loss: 0.0486 - val_accuracy: 0.9691 - val_loss: 0.1090\n",
            "Epoch 13/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9676 - loss: 0.0724 - val_accuracy: 0.9568 - val_loss: 0.1206\n",
            "Epoch 14/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9911 - loss: 0.0383 - val_accuracy: 0.9444 - val_loss: 0.1251\n",
            "Epoch 15/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9766 - loss: 0.0712 - val_accuracy: 0.9568 - val_loss: 0.1394\n",
            "Epoch 16/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9845 - loss: 0.0547 - val_accuracy: 0.9568 - val_loss: 0.1111\n",
            "Epoch 17/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9835 - loss: 0.0468 - val_accuracy: 0.9506 - val_loss: 0.1366\n",
            "Epoch 18/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9816 - loss: 0.0448 - val_accuracy: 0.9383 - val_loss: 0.1367\n",
            "Epoch 19/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9738 - loss: 0.0720 - val_accuracy: 0.9506 - val_loss: 0.1204\n",
            "Epoch 20/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9800 - loss: 0.0800 - val_accuracy: 0.9630 - val_loss: 0.1023\n",
            "Epoch 21/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9854 - loss: 0.0397 - val_accuracy: 0.9568 - val_loss: 0.1198\n",
            "Epoch 22/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9763 - loss: 0.0577 - val_accuracy: 0.9691 - val_loss: 0.0947\n",
            "Epoch 23/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9798 - loss: 0.0517 - val_accuracy: 0.9753 - val_loss: 0.0899\n",
            "Epoch 24/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9794 - loss: 0.0514 - val_accuracy: 0.9568 - val_loss: 0.0925\n",
            "Epoch 25/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9848 - loss: 0.0466 - val_accuracy: 0.9630 - val_loss: 0.0862\n",
            "Epoch 26/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9939 - loss: 0.0221 - val_accuracy: 0.9630 - val_loss: 0.0890\n",
            "Epoch 27/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9935 - loss: 0.0279 - val_accuracy: 0.9691 - val_loss: 0.0718\n",
            "Epoch 28/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9893 - loss: 0.0317 - val_accuracy: 0.9753 - val_loss: 0.0729\n",
            "Epoch 29/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9837 - loss: 0.0399 - val_accuracy: 0.9691 - val_loss: 0.0810\n",
            "Epoch 30/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9842 - loss: 0.0411 - val_accuracy: 0.9691 - val_loss: 0.0937\n",
            "Epoch 31/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9974 - loss: 0.0120 - val_accuracy: 0.9630 - val_loss: 0.1013\n",
            "Epoch 32/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9942 - loss: 0.0215 - val_accuracy: 0.9630 - val_loss: 0.0978\n",
            "Epoch 33/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9973 - loss: 0.0146 - val_accuracy: 0.9630 - val_loss: 0.1067\n",
            "Epoch 34/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9879 - loss: 0.0256 - val_accuracy: 0.9506 - val_loss: 0.1164\n",
            "Epoch 35/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9967 - loss: 0.0121 - val_accuracy: 0.9506 - val_loss: 0.1406\n",
            "Epoch 36/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9929 - loss: 0.0304 - val_accuracy: 0.9383 - val_loss: 0.1233\n",
            "Epoch 37/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0124 - val_accuracy: 0.9444 - val_loss: 0.1362\n",
            "Epoch 38/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9923 - loss: 0.0202 - val_accuracy: 0.9321 - val_loss: 0.2225\n",
            "Epoch 39/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0149 - val_accuracy: 0.9568 - val_loss: 0.1900\n",
            "Epoch 40/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9853 - loss: 0.0310 - val_accuracy: 0.9568 - val_loss: 0.1483\n",
            "Epoch 41/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9818 - loss: 0.0508 - val_accuracy: 0.9506 - val_loss: 0.1618\n",
            "Epoch 42/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9945 - loss: 0.0115 - val_accuracy: 0.9506 - val_loss: 0.1544\n",
            "Epoch 43/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9957 - loss: 0.0158 - val_accuracy: 0.9568 - val_loss: 0.1451\n",
            "Epoch 44/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9863 - loss: 0.0401 - val_accuracy: 0.9753 - val_loss: 0.1168\n",
            "Epoch 45/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9891 - loss: 0.0261 - val_accuracy: 0.9753 - val_loss: 0.1013\n",
            "Epoch 46/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9962 - loss: 0.0221 - val_accuracy: 0.9630 - val_loss: 0.1054\n",
            "Epoch 47/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9876 - loss: 0.0353 - val_accuracy: 0.9568 - val_loss: 0.1322\n",
            "Epoch 48/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9923 - loss: 0.0180 - val_accuracy: 0.9506 - val_loss: 0.1465\n",
            "Epoch 49/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9917 - loss: 0.0342 - val_accuracy: 0.9383 - val_loss: 0.1642\n",
            "Epoch 50/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9913 - loss: 0.0228 - val_accuracy: 0.9630 - val_loss: 0.1549\n",
            "Epoch 51/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9895 - loss: 0.0337 - val_accuracy: 0.9568 - val_loss: 0.1443\n",
            "Epoch 52/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9875 - loss: 0.0439 - val_accuracy: 0.9630 - val_loss: 0.1057\n",
            "Epoch 53/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9886 - loss: 0.0285 - val_accuracy: 0.9691 - val_loss: 0.0999\n",
            "Epoch 54/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9963 - loss: 0.0188 - val_accuracy: 0.9383 - val_loss: 0.1194\n",
            "Epoch 55/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9894 - loss: 0.0288 - val_accuracy: 0.9630 - val_loss: 0.1172\n",
            "Epoch 56/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9931 - loss: 0.0208 - val_accuracy: 0.9444 - val_loss: 0.2178\n",
            "Epoch 57/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9834 - loss: 0.0427 - val_accuracy: 0.9321 - val_loss: 0.1462\n",
            "Epoch 58/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9884 - loss: 0.0292 - val_accuracy: 0.9568 - val_loss: 0.1256\n",
            "Epoch 59/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9812 - loss: 0.0919 - val_accuracy: 0.9691 - val_loss: 0.1215\n",
            "Epoch 60/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9861 - loss: 0.0284 - val_accuracy: 0.9753 - val_loss: 0.1194\n",
            "Epoch 61/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9888 - loss: 0.0286 - val_accuracy: 0.9568 - val_loss: 0.1817\n",
            "Epoch 62/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9946 - loss: 0.0255 - val_accuracy: 0.9691 - val_loss: 0.1373\n",
            "Epoch 63/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9911 - loss: 0.0340 - val_accuracy: 0.9630 - val_loss: 0.1463\n",
            "Epoch 64/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9979 - loss: 0.0101 - val_accuracy: 0.9753 - val_loss: 0.1458\n",
            "Epoch 65/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9893 - loss: 0.0298 - val_accuracy: 0.9630 - val_loss: 0.1733\n",
            "Epoch 66/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9875 - loss: 0.0279 - val_accuracy: 0.9444 - val_loss: 0.1979\n",
            "Epoch 67/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9939 - loss: 0.0189 - val_accuracy: 0.9444 - val_loss: 0.1922\n",
            "Epoch 68/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9954 - loss: 0.0151 - val_accuracy: 0.9568 - val_loss: 0.2172\n",
            "Epoch 69/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9888 - loss: 0.0178 - val_accuracy: 0.9691 - val_loss: 0.1751\n",
            "Epoch 70/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9948 - loss: 0.0256 - val_accuracy: 0.9568 - val_loss: 0.1673\n",
            "Epoch 71/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9946 - loss: 0.0159 - val_accuracy: 0.9321 - val_loss: 0.1892\n",
            "Epoch 72/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9892 - loss: 0.0225 - val_accuracy: 0.9568 - val_loss: 0.1542\n",
            "Epoch 73/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9839 - loss: 0.0401 - val_accuracy: 0.9691 - val_loss: 0.1107\n",
            "Epoch 74/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 0.9753 - val_loss: 0.0869\n",
            "Epoch 75/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9947 - loss: 0.0175 - val_accuracy: 0.9815 - val_loss: 0.0839\n",
            "Epoch 76/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9969 - loss: 0.0116 - val_accuracy: 0.9753 - val_loss: 0.0930\n",
            "Epoch 77/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0145 - val_accuracy: 0.9630 - val_loss: 0.1837\n",
            "Epoch 78/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9920 - loss: 0.0305 - val_accuracy: 0.9506 - val_loss: 0.1272\n",
            "Epoch 79/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9910 - loss: 0.0288 - val_accuracy: 0.9630 - val_loss: 0.1126\n",
            "Epoch 80/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9946 - loss: 0.0139 - val_accuracy: 0.9630 - val_loss: 0.1129\n",
            "Epoch 81/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9918 - loss: 0.0232 - val_accuracy: 0.9691 - val_loss: 0.0955\n",
            "Epoch 82/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0173 - val_accuracy: 0.9630 - val_loss: 0.0882\n",
            "Epoch 83/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9959 - loss: 0.0162 - val_accuracy: 0.9691 - val_loss: 0.0973\n",
            "Epoch 84/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9901 - loss: 0.0373 - val_accuracy: 0.9691 - val_loss: 0.1066\n",
            "Epoch 85/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9963 - loss: 0.0084 - val_accuracy: 0.9568 - val_loss: 0.1120\n",
            "Epoch 86/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9822 - loss: 0.0407 - val_accuracy: 0.9506 - val_loss: 0.1385\n",
            "Epoch 87/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9881 - loss: 0.0303 - val_accuracy: 0.9753 - val_loss: 0.1159\n",
            "Epoch 88/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9943 - loss: 0.0120 - val_accuracy: 0.9506 - val_loss: 0.1240\n",
            "Epoch 89/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9986 - loss: 0.0079 - val_accuracy: 0.9444 - val_loss: 0.1196\n",
            "Epoch 90/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9889 - loss: 0.0246 - val_accuracy: 0.9444 - val_loss: 0.1311\n",
            "Epoch 91/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9970 - loss: 0.0080 - val_accuracy: 0.9568 - val_loss: 0.1088\n",
            "Epoch 92/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9931 - loss: 0.0159 - val_accuracy: 0.9691 - val_loss: 0.0816\n",
            "Epoch 93/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9949 - loss: 0.0123 - val_accuracy: 0.9815 - val_loss: 0.0879\n",
            "Epoch 94/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9947 - loss: 0.0248 - val_accuracy: 0.9630 - val_loss: 0.1081\n",
            "Epoch 95/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9804 - loss: 0.0424 - val_accuracy: 0.9630 - val_loss: 0.1355\n",
            "Epoch 96/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9898 - loss: 0.0157 - val_accuracy: 0.9691 - val_loss: 0.1389\n",
            "Epoch 97/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 0.0104 - val_accuracy: 0.9753 - val_loss: 0.1081\n",
            "Epoch 98/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0159 - val_accuracy: 0.9753 - val_loss: 0.0978\n",
            "Epoch 99/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9875 - loss: 0.0321 - val_accuracy: 0.9691 - val_loss: 0.1006\n",
            "Epoch 100/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9809 - loss: 0.0921 - val_accuracy: 0.9444 - val_loss: 0.1811\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9554 - loss: 0.1510 \n",
            "Test Accuracy: 0.9444\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          AI       0.94      0.95      0.95        86\n",
            "       HUMAN       0.95      0.93      0.94        76\n",
            "\n",
            "    accuracy                           0.94       162\n",
            "   macro avg       0.94      0.94      0.94       162\n",
            "weighted avg       0.94      0.94      0.94       162\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(256, input_dim=X_train_embeddings.shape[1], activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(label_encoder.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_embeddings, y_train_cat,\n",
        "    validation_data=(X_test_embeddings, y_test_cat),\n",
        "    epochs=100, batch_size=32\n",
        ")\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_embeddings, y_test_cat)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "y_pred = model.predict(X_test_embeddings)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "print(classification_report(y_test, y_pred_labels, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9w5SY75U493",
        "outputId": "c8fe15a2-ca4f-4209-de2e-58b88dfa1f31"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved as 'tamil_classification_model.h5'\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model.save(\"tamil_classification_model.h5\")\n",
        "print(\"Model saved as 'tamil_classification_model.h5'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DXNL0b07q5s"
      },
      "source": [
        "Malayalam use *bert-base-multilingual-cased*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjRr0Z5TTFZ-",
        "outputId": "05aeb45d-7c20-4e5d-9652-6521a2aa401c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label encoder saved to mal_label_encoder.pkl\n"
          ]
        }
      ],
      "source": [
        "\n",
        "file_path = \"/content/mal_training_data_hum_ai.csv\"\n",
        "dataset_df = pd.read_csv(file_path)\n",
        "dataset_df.columns = ['id', 'transcript', 'class_label']\n",
        "dataset_df\n",
        "\n",
        "stop = [\n",
        "    \"അവൻ\", \"അവൾ\", \"അവർ\", \"ആ\", \"ആകാം\", \"ആകുന്നു\", \"ആകും\", \"ആകെയുള്ള\", \"ആകെയുള്ളത്\", \"ആകെയുള്ളവ\", \"ആകെയുള്ളവർ\",\n",
        "    \"ആകെയുള്ളവൻ\", \"ആകെയുള്ളവൾ\", \"ആകെയുള്ളവൾക്ക്\", \"ആകുള്ളവൾക്ക്‌\", \"ഇത്\", \"ഇതിൽ\", \"ഇതിന്റെ\", \"ഇതും\", \"ഇതെല്ലാം\",\n",
        "    \"ഇവ\", \"ഇവയിൽ\", \"ഇവയുടെ\", \"ഇവയും\", \"ഇവയെല്ലാം\", \"ഇവൻ\", \"ഇവൾ\", \"ഇവർ\", \"ഇവരുടെ\", \"ഇവരിൽ\", \"ഇവരെയും\", \"ഇവരെയെല്ലാം\",\n",
        "    \"ഇവരോട്\", \"ഇവരോടും\", \"ഇവരോടുള്ള\", \"ഇവരോടുള്ളത്\", \"ഇവരോടുള്ളവ\", \"ഇവരോടുള്ളവർ\", \"ഇവരോടുള്ളവൻ\", \"ഇവരോടുള്ളവൾ\",\n",
        "    \"ഇവരോടുള്ളവൾക്ക്\", \"ഇവരോടുള്ളവൾക്ക്‌\"\n",
        "]\n",
        "\n",
        "def preprocess_malayalam_text(text):\n",
        "    \"\"\"Preprocess Malayalam text by normalizing, tokenizing, and removing stopwords.\"\"\"\n",
        "    normalizer_factory = IndicNormalizerFactory()\n",
        "    normalizer = normalizer_factory.get_normalizer(\"ml\")\n",
        "    text = normalizer.normalize(text)\n",
        "    tokens = list(indic_tokenize.trivial_tokenize(text, lang=\"ml\"))\n",
        "    tokens = [token for token in tokens if token not in stop]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "dataset_df['cleaned_transcript'] = dataset_df['transcript'].apply(preprocess_malayalam_text)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "dataset_df['encoded_label'] = label_encoder.fit_transform(dataset_df['class_label'])\n",
        "dataset_df\n",
        "\n",
        "label_encoder_path = \"mal_label_encoder.pkl\"\n",
        "with open(label_encoder_path, \"wb\") as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "print(f\"Label encoder saved to {label_encoder_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        },
        "id": "Zx-xI5xiWIxm",
        "outputId": "cd418312-49ed-44e6-cdb5-f1f43cc2ad6b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"dataset_df\",\n  \"rows\": 800,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 800,\n        \"samples\": [\n          \"MAL_HUAI_TR_697\",\n          \"MAL_HUAI_TR_668\",\n          \"MAL_HUAI_TR_064\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transcript\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 800,\n        \"samples\": [\n          \"\\u0d28\\u0d2e\\u0d41\\u0d15\\u0d4d\\u0d15\\u0d4d \\u0d15\\u0d23\\u0d4d\\u0d1f\\u0d35\\u0d7c \\u0d2a\\u0d31\\u0d1e\\u0d4d\\u0d1e\\u0d24\\u0d41\\u0d2a\\u0d4b\\u0d32\\u0d46, \\u0d08 \\u0d21\\u0d3f\\u0d2f\\u0d4b\\u0d21\\u0d3e\\u0d2a\\u0d4d\\u0d2a\\u0d4d \\u0d2a\\u0d4d\\u0d30\\u0d4b\\u0d21\\u0d15\\u0d4d\\u0d31\\u0d4d\\u0d31\\u0d41\\u0d15\\u0d7e \\u0d0e\\u0d32\\u0d4d\\u0d32\\u0d3e\\u0d02 \\u0d2c\\u0d4d\\u0d30\\u0d4b\\u0d15\\u0d4d\\u0d15\\u0d28\\u0d3e\\u0d23\\u0d4d, \\u0d05\\u0d1f\\u0d15\\u0d4d\\u0d15\\u0d02 \\u0d35\\u0d28\\u0d4d\\u0d28\\u0d3f\\u0d32\\u0d4d\\u0d32\\u0d3e\\u0d24\\u0d4d\\u0d24 \\u0d2a\\u0d4d\\u0d30\\u0d4b\\u0d21\\u0d15\\u0d4d\\u0d31\\u0d4d\\u0d31\\u0d41\\u0d15\\u0d33\\u0d41\\u0d02 \\u0d09\\u0d23\\u0d4d\\u0d1f\\u0d3e\\u0d15\\u0d3e\\u0d02.\",\n          \"\\u0d07\\u0d28\\u0d3f \\u0d06\\u0d2e\\u0d38\\u0d4b\\u0d23\\u0d3f\\u0d7d \\u0d28\\u0d3f\\u0d28\\u0d4d\\u0d28\\u0d4d \\u0d35\\u0d3e\\u0d19\\u0d4d\\u0d19\\u0d3f\\u0d2f \\u0d08 \\u0d38\\u0d4d\\u0d2e\\u0d3e\\u0d7c\\u0d1f\\u0d4d\\u0d1f\\u0d4d \\u0d35\\u0d3e\\u0d1a\\u0d4d\\u0d1a\\u0d4d \\u0d0e\\u0d28\\u0d4d\\u0d31\\u0d46 \\u0d21\\u0d46\\u0d2f\\u0d3f\\u0d32\\u0d3f \\u0d32\\u0d48\\u0d2b\\u0d4d \\u0d2e\\u0d3e\\u0d31\\u0d4d\\u0d31\\u0d3f\\u0d2e\\u0d31\\u0d3f\\u0d1a\\u0d4d\\u0d1a\\u0d3f\\u0d30\\u0d3f\\u0d15\\u0d4d\\u0d15\\u0d41\\u0d28\\u0d4d\\u0d28\\u0d41.\",\n          \"\\u0d37\\u0d48\\u0d7b \\u0d1f\\u0d4b\\u0d02 \\u0d1a\\u0d3e\\u0d15\\u0d4d\\u0d15\\u0d4b \\u0d2b\\u0d3e\\u0d7b \\u0d06\\u0d23\\u0d4d \\u0d1e\\u0d3e\\u0d7b.\\u0d07\\u0d28\\u0d4d\\u0d28\\u0d4d \\u0d2e\\u0d1e\\u0d4d\\u0d1a\\u0d47\\u0d30\\u0d3f \\u0d32\\u0d3e\\u0d21\\u0d7c \\u0d07\\u0d28\\u0d4d\\u0d24\\u0d4d\\u0d2f\\u0d7b \\u0d2e\\u0d3e\\u0d33\\u0d3f\\u0d7d \\u0d28\\u0d3f\\u0d28\\u0d4d\\u0d28\\u0d4d \\u0d30\\u0d23\\u0d4d\\u0d1f\\u0d4d \\u0d24\\u0d35\\u0d23 \\u0d15\\u0d23\\u0d4d\\u0d1f\\u0d41 \\u0d2a\\u0d1f\\u0d02 \\u0d28\\u0d3e\\u0d33\\u0d46\\u0d2f\\u0d41\\u0d02 \\u0d2a\\u0d4b\\u0d15\\u0d41\\u0d02. \\u0d2a\\u0d1f\\u0d02 \\u0d1a\\u0d3f\\u0d32\\u0d2a\\u0d4d\\u0d2a\\u0d4b\\u0d7e \\u0d2b\\u0d4d\\u0d32\\u0d4b\\u0d2a\\u0d4d\\u0d2a\\u0d4d \\u0d06\\u0d35\\u0d41\\u0d02. \\u0d2a\\u0d15\\u0d4d\\u0d37\\u0d46 \\u0d37\\u0d48\\u0d7b \\u0d1f\\u0d4b\\u0d02 \\u0d1a\\u0d3e\\u0d15\\u0d4d\\u0d15\\u0d4b\\u0d2f\\u0d46 \\u0d07\\u0d37\\u0d4d\\u0d1f\\u0d4d\\u0d1f\\u0d2e\\u0d3e\\u0d23\\u0d4d \\u0d08 \\u0d2a\\u0d1f\\u0d02 4 \\u0d24\\u0d35\\u0d23 \\u0d2a\\u0d4b\\u0d2f\\u0d3f \\u0d15\\u0d3e\\u0d23\\u0d23\\u0d02\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"AI\",\n          \"HUMAN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_transcript\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 800,\n        \"samples\": [\n          \"\\u0d28\\u0d2e\\u0d41\\u0d15\\u0d4d\\u0d15\\u0d4d \\u0d15\\u0d23\\u0d4d\\u0d1f\\u0d35\\u0d7c \\u0d2a\\u0d31\\u0d1e\\u0d4d\\u0d1e\\u0d24\\u0d41\\u0d2a\\u0d4b\\u0d32\\u0d46 , \\u0d08 \\u0d21\\u0d3f\\u0d2f\\u0d4b\\u0d21\\u0d3e\\u0d2a\\u0d4d\\u0d2a\\u0d4d \\u0d2a\\u0d4d\\u0d30\\u0d4b\\u0d21\\u0d15\\u0d4d\\u0d31\\u0d4d\\u0d31\\u0d41\\u0d15\\u0d7e \\u0d0e\\u0d32\\u0d4d\\u0d32\\u0d3e\\u0d02 \\u0d2c\\u0d4d\\u0d30\\u0d4b\\u0d15\\u0d4d\\u0d15\\u0d28\\u0d3e\\u0d23\\u0d4d , \\u0d05\\u0d1f\\u0d15\\u0d4d\\u0d15\\u0d02 \\u0d35\\u0d28\\u0d4d\\u0d28\\u0d3f\\u0d32\\u0d4d\\u0d32\\u0d3e\\u0d24\\u0d4d\\u0d24 \\u0d2a\\u0d4d\\u0d30\\u0d4b\\u0d21\\u0d15\\u0d4d\\u0d31\\u0d4d\\u0d31\\u0d41\\u0d15\\u0d33\\u0d41\\u0d02 \\u0d09\\u0d23\\u0d4d\\u0d1f\\u0d3e\\u0d15\\u0d3e\\u0d02 .\",\n          \"\\u0d07\\u0d28\\u0d3f \\u0d06\\u0d2e\\u0d38\\u0d4b\\u0d23\\u0d3f\\u0d7d \\u0d28\\u0d3f\\u0d28\\u0d4d\\u0d28\\u0d4d \\u0d35\\u0d3e\\u0d19\\u0d4d\\u0d19\\u0d3f\\u0d2f \\u0d08 \\u0d38\\u0d4d\\u0d2e\\u0d3e\\u0d7c\\u0d1f\\u0d4d\\u0d1f\\u0d4d \\u0d35\\u0d3e\\u0d1a\\u0d4d\\u0d1a\\u0d4d \\u0d0e\\u0d28\\u0d4d\\u0d31\\u0d46 \\u0d21\\u0d46\\u0d2f\\u0d3f\\u0d32\\u0d3f \\u0d32\\u0d48\\u0d2b\\u0d4d \\u0d2e\\u0d3e\\u0d31\\u0d4d\\u0d31\\u0d3f\\u0d2e\\u0d31\\u0d3f\\u0d1a\\u0d4d\\u0d1a\\u0d3f\\u0d30\\u0d3f\\u0d15\\u0d4d\\u0d15\\u0d41\\u0d28\\u0d4d\\u0d28\\u0d41 .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"encoded_label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "dataset_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-64c25bde-2133-499e-ad99-cc54680f32bf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>transcript</th>\n",
              "      <th>class_label</th>\n",
              "      <th>cleaned_transcript</th>\n",
              "      <th>encoded_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MAL_HUAI_TR_001</td>\n",
              "      <td>ഞാൻ കുറച്ച് കാലമായി മുച്ചട്ച്ചിൻ്റെ ഫേസ് വാഷ് ...</td>\n",
              "      <td>HUMAN</td>\n",
              "      <td>ഞാൻ കുറച്ച് കാലമായി മുച്ചട്ച്ചിൻ്റെ ഫേസ് വാഷ് ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MAL_HUAI_TR_002</td>\n",
              "      <td>ഈ ഫേസ് വാഷ് തണുപ്പ് വെതറിലും ഉപയോഗിക്കാം</td>\n",
              "      <td>HUMAN</td>\n",
              "      <td>ഈ ഫേസ് വാഷ് തണുപ്പ് വെതറിലും ഉപയോഗിക്കാം</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MAL_HUAI_TR_003</td>\n",
              "      <td>അണ്ണാ എനിക്ക് 14 വയസ് ആയ തേയോളു എനിക്ക് സ്കിൻക...</td>\n",
              "      <td>HUMAN</td>\n",
              "      <td>അണ്ണാ എനിക്ക് 14 വയസ് ആയ തേയോളു എനിക്ക് സ്കിൻക...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MAL_HUAI_TR_004</td>\n",
              "      <td>ബ്രോ ഇതെല്ലം യൂസ്  ആക്കീട്ട് നൈറ്റ് പിന്നെ വേറ...</td>\n",
              "      <td>HUMAN</td>\n",
              "      <td>ബ്രോ ഇതെല്ലം യൂസ് ആക്കീട്ട് നൈറ്റ് പിന്നെ വേറെ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MAL_HUAI_TR_005</td>\n",
              "      <td>ഇത് ഫേസ് വാഷ് ഡെയിലി ചെയ്താ സ്കിൻകെയറിന് നല്ലതാ</td>\n",
              "      <td>HUMAN</td>\n",
              "      <td>ഫേസ് വാഷ് ഡെയിലി ചെയ്താ സ്കിൻകെയറിന് നല്ലതാ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795</th>\n",
              "      <td>MAL_HUAI_TR_796</td>\n",
              "      <td>ബിരിയാണി, പപ്പടം, അച്ചാർ - മറ്റെവിടെയും കിട്ടാ...</td>\n",
              "      <td>AI</td>\n",
              "      <td>ബിരിയാണി , പപ്പടം , അച്ചാർ - മറ്റെവിടെയും കിട്...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>796</th>\n",
              "      <td>MAL_HUAI_TR_797</td>\n",
              "      <td>എങ്കിലും, തട്ടുകടയിലെ ഭക്ഷണത്തിന്റെ സുഖം മറ്റൊ...</td>\n",
              "      <td>AI</td>\n",
              "      <td>എങ്കിലും , തട്ടുകടയിലെ ഭക്ഷണത്തിന്റെ സുഖം മറ്റ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>797</th>\n",
              "      <td>MAL_HUAI_TR_798</td>\n",
              "      <td>പോറോട്ട, ബീഫ് കറി, സാലഡ് - ഈ കോമ്പിനേഷനിൽ നിന്...</td>\n",
              "      <td>AI</td>\n",
              "      <td>പോറോട്ട , ബീഫ് കറി , സാലഡ് - ഈ കോമ്പിനേഷനിൽ നി...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>MAL_HUAI_TR_799</td>\n",
              "      <td>നല്ല ഉഴുന്നുവട്ടിയും, കിടിലൻ ചമ്മന്തിയും ചേർന്...</td>\n",
              "      <td>AI</td>\n",
              "      <td>നല്ല ഉഴുന്നുവട്ടിയും , കിടിലൻ ചമ്മന്തിയും ചേർന...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>MAL_HUAI_TR_800</td>\n",
              "      <td>അങ്ങോട്ട് പോയാൽ, ചിക്കൻ കറി, ചപ്പാത്തി ഒന്നും ...</td>\n",
              "      <td>AI</td>\n",
              "      <td>അങ്ങോട്ട് പോയാൽ , ചിക്കൻ കറി , ചപ്പാത്തി ഒന്നു...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>800 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64c25bde-2133-499e-ad99-cc54680f32bf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-64c25bde-2133-499e-ad99-cc54680f32bf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-64c25bde-2133-499e-ad99-cc54680f32bf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f376f981-ca27-4853-b142-8789746fa37a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f376f981-ca27-4853-b142-8789746fa37a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f376f981-ca27-4853-b142-8789746fa37a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_91c841c9-7362-4883-893f-20a9c51056e5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dataset_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_91c841c9-7362-4883-893f-20a9c51056e5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dataset_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                  id                                         transcript  \\\n",
              "0    MAL_HUAI_TR_001  ഞാൻ കുറച്ച് കാലമായി മുച്ചട്ച്ചിൻ്റെ ഫേസ് വാഷ് ...   \n",
              "1    MAL_HUAI_TR_002           ഈ ഫേസ് വാഷ് തണുപ്പ് വെതറിലും ഉപയോഗിക്കാം   \n",
              "2    MAL_HUAI_TR_003  അണ്ണാ എനിക്ക് 14 വയസ് ആയ തേയോളു എനിക്ക് സ്കിൻക...   \n",
              "3    MAL_HUAI_TR_004  ബ്രോ ഇതെല്ലം യൂസ്  ആക്കീട്ട് നൈറ്റ് പിന്നെ വേറ...   \n",
              "4    MAL_HUAI_TR_005    ഇത് ഫേസ് വാഷ് ഡെയിലി ചെയ്താ സ്കിൻകെയറിന് നല്ലതാ   \n",
              "..               ...                                                ...   \n",
              "795  MAL_HUAI_TR_796  ബിരിയാണി, പപ്പടം, അച്ചാർ - മറ്റെവിടെയും കിട്ടാ...   \n",
              "796  MAL_HUAI_TR_797  എങ്കിലും, തട്ടുകടയിലെ ഭക്ഷണത്തിന്റെ സുഖം മറ്റൊ...   \n",
              "797  MAL_HUAI_TR_798  പോറോട്ട, ബീഫ് കറി, സാലഡ് - ഈ കോമ്പിനേഷനിൽ നിന്...   \n",
              "798  MAL_HUAI_TR_799  നല്ല ഉഴുന്നുവട്ടിയും, കിടിലൻ ചമ്മന്തിയും ചേർന്...   \n",
              "799  MAL_HUAI_TR_800  അങ്ങോട്ട് പോയാൽ, ചിക്കൻ കറി, ചപ്പാത്തി ഒന്നും ...   \n",
              "\n",
              "    class_label                                 cleaned_transcript  \\\n",
              "0         HUMAN  ഞാൻ കുറച്ച് കാലമായി മുച്ചട്ച്ചിൻ്റെ ഫേസ് വാഷ് ...   \n",
              "1         HUMAN           ഈ ഫേസ് വാഷ് തണുപ്പ് വെതറിലും ഉപയോഗിക്കാം   \n",
              "2         HUMAN  അണ്ണാ എനിക്ക് 14 വയസ് ആയ തേയോളു എനിക്ക് സ്കിൻക...   \n",
              "3         HUMAN  ബ്രോ ഇതെല്ലം യൂസ് ആക്കീട്ട് നൈറ്റ് പിന്നെ വേറെ...   \n",
              "4         HUMAN        ഫേസ് വാഷ് ഡെയിലി ചെയ്താ സ്കിൻകെയറിന് നല്ലതാ   \n",
              "..          ...                                                ...   \n",
              "795          AI  ബിരിയാണി , പപ്പടം , അച്ചാർ - മറ്റെവിടെയും കിട്...   \n",
              "796          AI  എങ്കിലും , തട്ടുകടയിലെ ഭക്ഷണത്തിന്റെ സുഖം മറ്റ...   \n",
              "797          AI  പോറോട്ട , ബീഫ് കറി , സാലഡ് - ഈ കോമ്പിനേഷനിൽ നി...   \n",
              "798          AI  നല്ല ഉഴുന്നുവട്ടിയും , കിടിലൻ ചമ്മന്തിയും ചേർന...   \n",
              "799          AI  അങ്ങോട്ട് പോയാൽ , ചിക്കൻ കറി , ചപ്പാത്തി ഒന്നു...   \n",
              "\n",
              "     encoded_label  \n",
              "0                1  \n",
              "1                1  \n",
              "2                1  \n",
              "3                1  \n",
              "4                1  \n",
              "..             ...  \n",
              "795              0  \n",
              "796              0  \n",
              "797              0  \n",
              "798              0  \n",
              "799              0  \n",
              "\n",
              "[800 rows x 5 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diqRudW4V6q9"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    dataset_df['cleaned_transcript'], dataset_df['encoded_label'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "def extract_embeddings(model_name, texts):\n",
        "    \"\"\"Extract embeddings for the given texts using a pre-trained transformer model.\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModel.from_pretrained(model_name).to(device)\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "    batch_size = 16\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(texts), batch_size):\n",
        "            batch_texts = texts[i:i+batch_size]\n",
        "            encoded_inputs = tokenizer(batch_texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "            encoded_inputs = {key: tensor.to(device) for key, tensor in encoded_inputs.items()}\n",
        "            outputs = model(**encoded_inputs)\n",
        "            batch_embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "            embeddings.extend(batch_embeddings)\n",
        "    return np.array(embeddings)\n",
        "\n",
        "X_train_embeddings = extract_embeddings(\"bert-base-multilingual-cased\", X_train.tolist())\n",
        "X_test_embeddings = extract_embeddings(\"bert-base-multilingual-cased\", X_test.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "quJIFfGGWLxJ",
        "outputId": "a583c226-8781-47e7-c257-912d876a5dcc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m196,864\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m258\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">231,554</span> (904.51 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m231,554\u001b[0m (904.51 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">230,786</span> (901.51 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m230,786\u001b[0m (901.51 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.6741 - loss: 0.8844 - val_accuracy: 0.9250 - val_loss: 0.3991\n",
            "Epoch 2/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8918 - loss: 0.2624 - val_accuracy: 0.9438 - val_loss: 0.3021\n",
            "Epoch 3/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9336 - loss: 0.1865 - val_accuracy: 0.9563 - val_loss: 0.2358\n",
            "Epoch 4/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9368 - loss: 0.1457 - val_accuracy: 0.9438 - val_loss: 0.2133\n",
            "Epoch 5/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9398 - loss: 0.1572 - val_accuracy: 0.9438 - val_loss: 0.1829\n",
            "Epoch 6/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9346 - loss: 0.1697 - val_accuracy: 0.9375 - val_loss: 0.1689\n",
            "Epoch 7/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9566 - loss: 0.1053 - val_accuracy: 0.9563 - val_loss: 0.1482\n",
            "Epoch 8/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9497 - loss: 0.1277 - val_accuracy: 0.9438 - val_loss: 0.1458\n",
            "Epoch 9/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9664 - loss: 0.0891 - val_accuracy: 0.9438 - val_loss: 0.1436\n",
            "Epoch 10/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9580 - loss: 0.1017 - val_accuracy: 0.9625 - val_loss: 0.1359\n",
            "Epoch 11/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9631 - loss: 0.0826 - val_accuracy: 0.9563 - val_loss: 0.1404\n",
            "Epoch 12/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9747 - loss: 0.0656 - val_accuracy: 0.9500 - val_loss: 0.1457\n",
            "Epoch 13/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9583 - loss: 0.1143 - val_accuracy: 0.9312 - val_loss: 0.2020\n",
            "Epoch 14/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9752 - loss: 0.0729 - val_accuracy: 0.9563 - val_loss: 0.1322\n",
            "Epoch 15/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9887 - loss: 0.0414 - val_accuracy: 0.9500 - val_loss: 0.1439\n",
            "Epoch 16/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9644 - loss: 0.1101 - val_accuracy: 0.9625 - val_loss: 0.1563\n",
            "Epoch 17/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9741 - loss: 0.0739 - val_accuracy: 0.9563 - val_loss: 0.1576\n",
            "Epoch 18/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9724 - loss: 0.0584 - val_accuracy: 0.9375 - val_loss: 0.2326\n",
            "Epoch 19/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9730 - loss: 0.0579 - val_accuracy: 0.9375 - val_loss: 0.2252\n",
            "Epoch 20/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9882 - loss: 0.0446 - val_accuracy: 0.9500 - val_loss: 0.1351\n",
            "Epoch 21/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9784 - loss: 0.0467 - val_accuracy: 0.9563 - val_loss: 0.2320\n",
            "Epoch 22/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9812 - loss: 0.0483 - val_accuracy: 0.9438 - val_loss: 0.1855\n",
            "Epoch 23/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9937 - loss: 0.0302 - val_accuracy: 0.9500 - val_loss: 0.1742\n",
            "Epoch 24/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9886 - loss: 0.0391 - val_accuracy: 0.9500 - val_loss: 0.2524\n",
            "Epoch 25/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9931 - loss: 0.0288 - val_accuracy: 0.9500 - val_loss: 0.2129\n",
            "Epoch 26/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9874 - loss: 0.0365 - val_accuracy: 0.9625 - val_loss: 0.2323\n",
            "Epoch 27/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9930 - loss: 0.0227 - val_accuracy: 0.9625 - val_loss: 0.1871\n",
            "Epoch 28/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9895 - loss: 0.0251 - val_accuracy: 0.9563 - val_loss: 0.1732\n",
            "Epoch 29/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9845 - loss: 0.0368 - val_accuracy: 0.9625 - val_loss: 0.1852\n",
            "Epoch 30/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9937 - loss: 0.0181 - val_accuracy: 0.9563 - val_loss: 0.1721\n",
            "Epoch 31/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9850 - loss: 0.0351 - val_accuracy: 0.9438 - val_loss: 0.2461\n",
            "Epoch 32/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9943 - loss: 0.0187 - val_accuracy: 0.9438 - val_loss: 0.1971\n",
            "Epoch 33/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0208 - val_accuracy: 0.9500 - val_loss: 0.1865\n",
            "Epoch 34/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9898 - loss: 0.0287 - val_accuracy: 0.9375 - val_loss: 0.2504\n",
            "Epoch 35/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9851 - loss: 0.0373 - val_accuracy: 0.9438 - val_loss: 0.1743\n",
            "Epoch 36/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9770 - loss: 0.0500 - val_accuracy: 0.9375 - val_loss: 0.2301\n",
            "Epoch 37/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9885 - loss: 0.0389 - val_accuracy: 0.9375 - val_loss: 0.2249\n",
            "Epoch 38/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9835 - loss: 0.0299 - val_accuracy: 0.9312 - val_loss: 0.2243\n",
            "Epoch 39/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9866 - loss: 0.0302 - val_accuracy: 0.9250 - val_loss: 0.2605\n",
            "Epoch 40/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9826 - loss: 0.0593 - val_accuracy: 0.9438 - val_loss: 0.1897\n",
            "Epoch 41/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9848 - loss: 0.0438 - val_accuracy: 0.9438 - val_loss: 0.2150\n",
            "Epoch 42/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9850 - loss: 0.0288 - val_accuracy: 0.9563 - val_loss: 0.2026\n",
            "Epoch 43/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9892 - loss: 0.0259 - val_accuracy: 0.9438 - val_loss: 0.2219\n",
            "Epoch 44/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9814 - loss: 0.0390 - val_accuracy: 0.9375 - val_loss: 0.2075\n",
            "Epoch 45/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9692 - loss: 0.0886 - val_accuracy: 0.9438 - val_loss: 0.2153\n",
            "Epoch 46/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9919 - loss: 0.0262 - val_accuracy: 0.9438 - val_loss: 0.2100\n",
            "Epoch 47/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9934 - loss: 0.0185 - val_accuracy: 0.9438 - val_loss: 0.2292\n",
            "Epoch 48/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9910 - loss: 0.0416 - val_accuracy: 0.9312 - val_loss: 0.2756\n",
            "Epoch 49/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9945 - loss: 0.0211 - val_accuracy: 0.9563 - val_loss: 0.2057\n",
            "Epoch 50/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9977 - loss: 0.0149 - val_accuracy: 0.9438 - val_loss: 0.2398\n",
            "Epoch 51/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9981 - loss: 0.0134 - val_accuracy: 0.9187 - val_loss: 0.4069\n",
            "Epoch 52/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9952 - loss: 0.0186 - val_accuracy: 0.9438 - val_loss: 0.2552\n",
            "Epoch 53/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9965 - loss: 0.0148 - val_accuracy: 0.9500 - val_loss: 0.2410\n",
            "Epoch 54/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9985 - loss: 0.0144 - val_accuracy: 0.9438 - val_loss: 0.2735\n",
            "Epoch 55/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9873 - loss: 0.0267 - val_accuracy: 0.9438 - val_loss: 0.3432\n",
            "Epoch 56/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9905 - loss: 0.0254 - val_accuracy: 0.9438 - val_loss: 0.3174\n",
            "Epoch 57/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9907 - loss: 0.0156 - val_accuracy: 0.9375 - val_loss: 0.3295\n",
            "Epoch 58/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9950 - loss: 0.0287 - val_accuracy: 0.9250 - val_loss: 0.4139\n",
            "Epoch 59/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9925 - loss: 0.0243 - val_accuracy: 0.9563 - val_loss: 0.2498\n",
            "Epoch 60/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9959 - loss: 0.0179 - val_accuracy: 0.9250 - val_loss: 0.3647\n",
            "Epoch 61/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9916 - loss: 0.0186 - val_accuracy: 0.9250 - val_loss: 0.3160\n",
            "Epoch 62/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9986 - loss: 0.0081 - val_accuracy: 0.9438 - val_loss: 0.2454\n",
            "Epoch 63/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9938 - loss: 0.0149 - val_accuracy: 0.9500 - val_loss: 0.2370\n",
            "Epoch 64/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9932 - loss: 0.0138 - val_accuracy: 0.9375 - val_loss: 0.2727\n",
            "Epoch 65/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9883 - loss: 0.0252 - val_accuracy: 0.9312 - val_loss: 0.3065\n",
            "Epoch 66/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9977 - loss: 0.0079 - val_accuracy: 0.9187 - val_loss: 0.3739\n",
            "Epoch 67/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9949 - loss: 0.0188 - val_accuracy: 0.9563 - val_loss: 0.2253\n",
            "Epoch 68/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9972 - loss: 0.0130 - val_accuracy: 0.9563 - val_loss: 0.2474\n",
            "Epoch 69/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0112 - val_accuracy: 0.9438 - val_loss: 0.2625\n",
            "Epoch 70/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9897 - loss: 0.0202 - val_accuracy: 0.9438 - val_loss: 0.2408\n",
            "Epoch 71/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9888 - loss: 0.0240 - val_accuracy: 0.9500 - val_loss: 0.2426\n",
            "Epoch 72/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9940 - loss: 0.0198 - val_accuracy: 0.9312 - val_loss: 0.3909\n",
            "Epoch 73/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9990 - loss: 0.0060 - val_accuracy: 0.9438 - val_loss: 0.3474\n",
            "Epoch 74/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9952 - loss: 0.0173 - val_accuracy: 0.9500 - val_loss: 0.2642\n",
            "Epoch 75/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9787 - loss: 0.0671 - val_accuracy: 0.9563 - val_loss: 0.2653\n",
            "Epoch 76/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9929 - loss: 0.0245 - val_accuracy: 0.9375 - val_loss: 0.2658\n",
            "Epoch 77/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0124 - val_accuracy: 0.9312 - val_loss: 0.2878\n",
            "Epoch 78/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9922 - loss: 0.0142 - val_accuracy: 0.9312 - val_loss: 0.3067\n",
            "Epoch 79/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9978 - loss: 0.0092 - val_accuracy: 0.9375 - val_loss: 0.3102\n",
            "Epoch 80/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9855 - loss: 0.0323 - val_accuracy: 0.9563 - val_loss: 0.2426\n",
            "Epoch 81/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9941 - loss: 0.0163 - val_accuracy: 0.9500 - val_loss: 0.2898\n",
            "Epoch 82/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0100 - val_accuracy: 0.9312 - val_loss: 0.3717\n",
            "Epoch 83/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9992 - loss: 0.0084 - val_accuracy: 0.9250 - val_loss: 0.4139\n",
            "Epoch 84/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9910 - loss: 0.0144 - val_accuracy: 0.9250 - val_loss: 0.3443\n",
            "Epoch 85/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9887 - loss: 0.0203 - val_accuracy: 0.9375 - val_loss: 0.3236\n",
            "Epoch 86/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9926 - loss: 0.0176 - val_accuracy: 0.9438 - val_loss: 0.2856\n",
            "Epoch 87/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9953 - loss: 0.0120 - val_accuracy: 0.9312 - val_loss: 0.3520\n",
            "Epoch 88/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9962 - loss: 0.0115 - val_accuracy: 0.9500 - val_loss: 0.2596\n",
            "Epoch 89/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9931 - loss: 0.0124 - val_accuracy: 0.9563 - val_loss: 0.2456\n",
            "Epoch 90/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9934 - loss: 0.0256 - val_accuracy: 0.9312 - val_loss: 0.2910\n",
            "Epoch 91/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9968 - loss: 0.0122 - val_accuracy: 0.9438 - val_loss: 0.2718\n",
            "Epoch 92/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0183 - val_accuracy: 0.9312 - val_loss: 0.3059\n",
            "Epoch 93/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9868 - loss: 0.0428 - val_accuracy: 0.9500 - val_loss: 0.2915\n",
            "Epoch 94/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9899 - loss: 0.0285 - val_accuracy: 0.9500 - val_loss: 0.2696\n",
            "Epoch 95/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0133 - val_accuracy: 0.9312 - val_loss: 0.3004\n",
            "Epoch 96/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9872 - loss: 0.0201 - val_accuracy: 0.9375 - val_loss: 0.2893\n",
            "Epoch 97/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9884 - loss: 0.0277 - val_accuracy: 0.9438 - val_loss: 0.2788\n",
            "Epoch 98/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9948 - loss: 0.0125 - val_accuracy: 0.9438 - val_loss: 0.3269\n",
            "Epoch 99/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9951 - loss: 0.0157 - val_accuracy: 0.9312 - val_loss: 0.3070\n",
            "Epoch 100/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0052 - val_accuracy: 0.9375 - val_loss: 0.2790\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9440 - loss: 0.2187 \n",
            "Test Accuracy: 0.9375\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          AI       0.92      0.96      0.94        80\n",
            "       HUMAN       0.96      0.91      0.94        80\n",
            "\n",
            "    accuracy                           0.94       160\n",
            "   macro avg       0.94      0.94      0.94       160\n",
            "weighted avg       0.94      0.94      0.94       160\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(256, input_dim=X_train_embeddings.shape[1], activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(label_encoder.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_embeddings, y_train_cat,\n",
        "    validation_data=(X_test_embeddings, y_test_cat),\n",
        "    epochs=100, batch_size=32\n",
        ")\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_embeddings, y_test_cat)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "y_pred = model.predict(X_test_embeddings)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "print(classification_report(y_test, y_pred_labels, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Axio255KWQ2n",
        "outputId": "475828e3-2177-4252-a4ba-31f34e695d72"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved as 'Mala_classification_model.h5'\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model.save(\"Mala_classification_model.h5\")\n",
        "print(\"Model saved as 'Mala_classification_model.h5'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oav-xgbfW8xQ",
        "outputId": "5419865d-4212-4948-9ada-4e1645ff5172"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Test dataset loaded.\n",
            "Label encoder loaded from /content/tamil_label_encoder.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings generated for test data.\n",
            "Model loaded from /content/tamil_classification_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7aa161438ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Predictions saved to ./tam_test_predictions_simple.tsv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "test_file_path = \"/content/tam_test_data_hum_ai.xlsx\"\n",
        "test_df = pd.read_excel(test_file_path)\n",
        "\n",
        "test_df.columns = ['id', 'transcript']\n",
        "print(\"Test dataset loaded.\")\n",
        "\n",
        "test_df['cleaned_transcript'] = test_df['transcript'].apply(preprocess_tamil_text)\n",
        "\n",
        "label_encoder_path = \"/content/tamil_label_encoder.pkl\"\n",
        "with open(label_encoder_path, \"rb\") as f:\n",
        "    label_encoder = pickle.load(f)\n",
        "print(f\"Label encoder loaded from {label_encoder_path}\")\n",
        "\n",
        "def extract_embeddings(model_name, texts):\n",
        "    \"\"\"Extract embeddings for the given texts using a pre-trained transformer model.\"\"\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModel.from_pretrained(model_name).to(device)\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "    batch_size = 16\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(texts), batch_size):\n",
        "            batch_texts = texts[i:i+batch_size]\n",
        "            encoded_inputs = tokenizer(batch_texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "            encoded_inputs = {key: tensor.to(device) for key, tensor in encoded_inputs.items()}\n",
        "            outputs = model(**encoded_inputs)\n",
        "            batch_embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "            embeddings.extend(batch_embeddings)\n",
        "    return np.array(embeddings)\n",
        "\n",
        "X_test_embeddings = extract_embeddings(\"bert-base-multilingual-cased\", test_df['cleaned_transcript'].tolist())\n",
        "print(\"Embeddings generated for test data.\")\n",
        "\n",
        "model_path = \"/content/tamil_classification_model.h5\"  \n",
        "model = load_model(model_path)\n",
        "print(f\"Model loaded from {model_path}\")\n",
        "\n",
        "y_pred = model.predict(X_test_embeddings)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "test_df['predicted_label'] = label_encoder.inverse_transform(y_pred_labels)\n",
        "\n",
        "output_file_path_tsv = \"./tam_test_predictions_simple.tsv\"\n",
        "output_df = test_df[['id', 'predicted_label']]\n",
        "output_df.to_csv(output_file_path_tsv, sep='\\t', index=False)\n",
        "\n",
        "print(f\"Predictions saved to {output_file_path_tsv}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkQ-U184W801",
        "outputId": "ee984f6b-2218-47a6-9475-52551f43a8bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Test dataset loaded.\n",
            "Label encoder loaded from /content/mal_label_encoder.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings generated for test data.\n",
            "Model loaded from /content/Mala_classification_model.h5\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Predictions saved to ./mal_test_predictions_simple.tsv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "test_file_path = \"/content/mal_test_data_hum_ai.xlsx\"\n",
        "test_df = pd.read_excel(test_file_path)\n",
        "\n",
        "test_df.columns = ['id', 'transcript']\n",
        "print(\"Test dataset loaded.\")\n",
        "\n",
        "test_df['cleaned_transcript'] = test_df['transcript'].apply(preprocess_tamil_text)\n",
        "\n",
        "label_encoder_path = \"/content/mal_label_encoder.pkl\"\n",
        "with open(label_encoder_path, \"rb\") as f:\n",
        "    label_encoder = pickle.load(f)\n",
        "print(f\"Label encoder loaded from {label_encoder_path}\")\n",
        "\n",
        "def extract_embeddings(model_name, texts):\n",
        "    \"\"\"Extract embeddings for the given texts using a pre-trained transformer model.\"\"\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModel.from_pretrained(model_name).to(device)\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "    batch_size = 16\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(texts), batch_size):\n",
        "            batch_texts = texts[i:i+batch_size]\n",
        "            encoded_inputs = tokenizer(batch_texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "            encoded_inputs = {key: tensor.to(device) for key, tensor in encoded_inputs.items()}\n",
        "            outputs = model(**encoded_inputs)\n",
        "            batch_embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "            embeddings.extend(batch_embeddings)\n",
        "    return np.array(embeddings)\n",
        "\n",
        "X_test_embeddings = extract_embeddings(\"bert-base-multilingual-cased\", test_df['cleaned_transcript'].tolist())\n",
        "print(\"Embeddings generated for test data.\")\n",
        "\n",
        "model_path = \"/content/Mala_classification_model.h5\"  \n",
        "model = load_model(model_path)\n",
        "print(f\"Model loaded from {model_path}\")\n",
        "\n",
        "y_pred = model.predict(X_test_embeddings)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "test_df['predicted_label'] = label_encoder.inverse_transform(y_pred_labels)\n",
        "\n",
        "output_file_path_tsv = \"./mal_test_predictions_simple.tsv\"\n",
        "output_df = test_df[['id', 'predicted_label']]\n",
        "output_df.to_csv(output_file_path_tsv, sep='\\t', index=False)\n",
        "\n",
        "print(f\"Predictions saved to {output_file_path_tsv}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VF64SU2ZsH1",
        "outputId": "0c245010-93d3-4bf3-f795-c24b0ce1b940"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TSV File Contents:\n",
            "                 id predicted_label\n",
            "0   TAM_HUAI_TE_001           HUMAN\n",
            "1   TAM_HUAI_TE_002           HUMAN\n",
            "2   TAM_HUAI_TE_003           HUMAN\n",
            "3   TAM_HUAI_TE_004           HUMAN\n",
            "4   TAM_HUAI_TE_005           HUMAN\n",
            "..              ...             ...\n",
            "95  TAM_HUAI_TE_096           HUMAN\n",
            "96  TAM_HUAI_TE_097           HUMAN\n",
            "97  TAM_HUAI_TE_098           HUMAN\n",
            "98  TAM_HUAI_TE_099           HUMAN\n",
            "99  TAM_HUAI_TE_100           HUMAN\n",
            "\n",
            "[100 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "tsv_file_path = \"/content/tam_test_predictions_simple.tsv\"\n",
        "\n",
        "df_tsv = pd.read_csv(tsv_file_path, sep='\\t')\n",
        "\n",
        "print(\"TSV File Contents:\")\n",
        "print(df_tsv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQ3PVpjJZxIL",
        "outputId": "41e5b95a-3d43-4cd3-a0f6-0ced5344a975"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TSV File Contents:\n",
            "                  id predicted_label\n",
            "0    MAL_HUAI_TE_001           HUMAN\n",
            "1    MAL_HUAI_TE_002           HUMAN\n",
            "2    MAL_HUAI_TE_003           HUMAN\n",
            "3    MAL_HUAI_TE_004           HUMAN\n",
            "4    MAL_HUAI_TE_005           HUMAN\n",
            "..               ...             ...\n",
            "195  MAL_HUAI_TE_196              AI\n",
            "196  MAL_HUAI_TE_197              AI\n",
            "197  MAL_HUAI_TE_198              AI\n",
            "198  MAL_HUAI_TE_199           HUMAN\n",
            "199  MAL_HUAI_TE_200              AI\n",
            "\n",
            "[200 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "tsv_file_path = \"/content/mal_test_predictions_simple.tsv\"\n",
        "\n",
        "df_tsv = pd.read_csv(tsv_file_path, sep='\\t')\n",
        "\n",
        "print(\"TSV File Contents:\")\n",
        "print(df_tsv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI8jDBj5JeNR"
      },
      "source": [
        "Tamil CountVectorizer and TFIDFVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTwYpU7DaGmw",
        "outputId": "d63b052a-e424-47da-9cae-5ecee2a31b9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Collecting indic-nlp-library\n",
            "  Downloading indic_nlp_library-0.92-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting advertools\n",
            "  Downloading advertools-0.16.4-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Collecting sphinx-argparse (from indic-nlp-library)\n",
            "  Downloading sphinx_argparse-0.5.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting sphinx-rtd-theme (from indic-nlp-library)\n",
            "  Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting morfessor (from indic-nlp-library)\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library) (2.2.2)\n",
            "Requirement already satisfied: pyasn1>=0.4 in /usr/local/lib/python3.11/dist-packages (from advertools) (0.6.1)\n",
            "Collecting scrapy>=2.5.0 (from advertools)\n",
            "  Downloading Scrapy-2.12.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting twython>=3.8.0 (from advertools)\n",
            "  Downloading twython-3.9.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from advertools) (17.0.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Collecting Twisted>=21.7.0 (from scrapy>=2.5.0->advertools)\n",
            "  Downloading twisted-24.11.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: cryptography>=37.0.0 in /usr/local/lib/python3.11/dist-packages (from scrapy>=2.5.0->advertools) (43.0.3)\n",
            "Collecting cssselect>=0.9.1 (from scrapy>=2.5.0->advertools)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting itemloaders>=1.0.1 (from scrapy>=2.5.0->advertools)\n",
            "  Downloading itemloaders-1.3.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting parsel>=1.5.0 (from scrapy>=2.5.0->advertools)\n",
            "  Downloading parsel-1.10.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyOpenSSL>=22.0.0 in /usr/local/lib/python3.11/dist-packages (from scrapy>=2.5.0->advertools) (24.2.1)\n",
            "Collecting queuelib>=1.4.2 (from scrapy>=2.5.0->advertools)\n",
            "  Downloading queuelib-1.7.0-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting service-identity>=18.1.0 (from scrapy>=2.5.0->advertools)\n",
            "  Downloading service_identity-24.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting w3lib>=1.17.0 (from scrapy>=2.5.0->advertools)\n",
            "  Downloading w3lib-2.3.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting zope.interface>=5.1.0 (from scrapy>=2.5.0->advertools)\n",
            "  Downloading zope.interface-7.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protego>=0.1.15 (from scrapy>=2.5.0->advertools)\n",
            "  Downloading Protego-0.4.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting itemadapter>=0.1.0 (from scrapy>=2.5.0->advertools)\n",
            "  Downloading itemadapter-0.10.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting tldextract (from scrapy>=2.5.0->advertools)\n",
            "  Downloading tldextract-5.1.3-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: lxml>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from scrapy>=2.5.0->advertools) (5.3.0)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from scrapy>=2.5.0->advertools) (0.7.1)\n",
            "Collecting PyDispatcher>=2.0.5 (from scrapy>=2.5.0->advertools)\n",
            "  Downloading PyDispatcher-2.0.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from twython>=3.8.0->advertools) (1.3.1)\n",
            "Requirement already satisfied: sphinx>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from sphinx-argparse->indic-nlp-library) (8.1.3)\n",
            "Requirement already satisfied: docutils>=0.19 in /usr/local/lib/python3.11/dist-packages (from sphinx-argparse->indic-nlp-library) (0.21.2)\n",
            "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->indic-nlp-library)\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=37.0.0->scrapy>=2.5.0->advertools) (1.17.1)\n",
            "Collecting jmespath>=0.9.5 (from itemloaders>=1.0.1->scrapy>=2.5.0->advertools)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.17.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.4.0->twython>=3.8.0->advertools) (3.2.2)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from service-identity>=18.1.0->scrapy>=2.5.0->advertools) (24.3.0)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.11/dist-packages (from service-identity>=18.1.0->scrapy>=2.5.0->advertools) (0.4.1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: Jinja2>=3.1 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.5)\n",
            "Requirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.18.0)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.16.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
            "Collecting automat>=24.8.0 (from Twisted>=21.7.0->scrapy>=2.5.0->advertools)\n",
            "  Downloading Automat-24.8.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting constantly>=15.1 (from Twisted>=21.7.0->scrapy>=2.5.0->advertools)\n",
            "  Downloading constantly-23.10.4-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting hyperlink>=17.1.1 (from Twisted>=21.7.0->scrapy>=2.5.0->advertools)\n",
            "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting incremental>=24.7.0 (from Twisted>=21.7.0->scrapy>=2.5.0->advertools)\n",
            "  Downloading incremental-24.7.2-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from zope.interface>=5.1.0->scrapy>=2.5.0->advertools) (75.1.0)\n",
            "Collecting requests-file>=1.4 (from tldextract->scrapy>=2.5.0->advertools)\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=37.0.0->scrapy>=2.5.0->advertools) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.0.2)\n",
            "Downloading indic_nlp_library-0.92-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading advertools-0.16.4-py2.py3-none-any.whl (408 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.7/408.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Scrapy-2.12.0-py2.py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading twython-3.9.1-py3-none-any.whl (33 kB)\n",
            "Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Downloading sphinx_argparse-0.5.2-py3-none-any.whl (12 kB)\n",
            "Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading itemadapter-0.10.0-py3-none-any.whl (11 kB)\n",
            "Downloading itemloaders-1.3.2-py3-none-any.whl (12 kB)\n",
            "Downloading parsel-1.10.0-py2.py3-none-any.whl (17 kB)\n",
            "Downloading Protego-0.4.0-py2.py3-none-any.whl (8.6 kB)\n",
            "Downloading PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n",
            "Downloading queuelib-1.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading service_identity-24.2.0-py3-none-any.whl (11 kB)\n",
            "Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading twisted-24.11.0-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading w3lib-2.3.1-py3-none-any.whl (21 kB)\n",
            "Downloading zope.interface-7.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.8/259.8 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tldextract-5.1.3-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Automat-24.8.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading constantly-23.10.4-py3-none-any.whl (13 kB)\n",
            "Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading incremental-24.7.2-py3-none-any.whl (20 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Installing collected packages: PyDispatcher, morfessor, zope.interface, w3lib, queuelib, protego, jmespath, itemadapter, incremental, hyperlink, cssselect, constantly, automat, Twisted, requests-file, parsel, twython, tldextract, sphinxcontrib-jquery, sphinx-argparse, service-identity, itemloaders, sphinx-rtd-theme, scrapy, indic-nlp-library, advertools\n",
            "Successfully installed PyDispatcher-2.0.7 Twisted-24.11.0 advertools-0.16.4 automat-24.8.1 constantly-23.10.4 cssselect-1.2.0 hyperlink-21.0.0 incremental-24.7.2 indic-nlp-library-0.92 itemadapter-0.10.0 itemloaders-1.3.2 jmespath-1.0.1 morfessor-2.0.6 parsel-1.10.0 protego-0.4.0 queuelib-1.7.0 requests-file-2.1.0 scrapy-2.12.0 service-identity-24.2.0 sphinx-argparse-0.5.2 sphinx-rtd-theme-3.0.2 sphinxcontrib-jquery-4.1 tldextract-5.1.3 twython-3.9.1 w3lib-2.3.1 zope.interface-7.2\n",
            "                id                                         transcript  \\\n",
            "0  TAM_HUAI_TR_001  இந்த சோப்பின் மணம் மிகவும் புத்துணர்ச்சியூட்டு...   \n",
            "1  TAM_HUAI_TR_002   தோலை நன்கு சுத்தம் செய்ய இது மிகவும் சிறப்பானது.   \n",
            "2  TAM_HUAI_TR_003  இதைப் பயன்படுத்திய பிறகு, தோல் மிக மென்மையாக உ...   \n",
            "3  TAM_HUAI_TR_004  இந்த சோப்பில் இயற்கையான மூலப்பொருட்கள் பயன்படு...   \n",
            "4  TAM_HUAI_TR_005        சிறிது சோப்பு போதும், அதிக நுரை உருவாகிறது.   \n",
            "\n",
            "  class_label  \n",
            "0          AI  \n",
            "1          AI  \n",
            "2          AI  \n",
            "3          AI  \n",
            "4          AI  \n",
            "                id                                         transcript  \\\n",
            "0  TAM_HUAI_TR_001  இந்த சோப்பின் மணம் மிகவும் புத்துணர்ச்சியூட்டு...   \n",
            "1  TAM_HUAI_TR_002   தோலை நன்கு சுத்தம் செய்ய இது மிகவும் சிறப்பானது.   \n",
            "2  TAM_HUAI_TR_003  இதைப் பயன்படுத்திய பிறகு, தோல் மிக மென்மையாக உ...   \n",
            "3  TAM_HUAI_TR_004  இந்த சோப்பில் இயற்கையான மூலப்பொருட்கள் பயன்படு...   \n",
            "4  TAM_HUAI_TR_005        சிறிது சோப்பு போதும், அதிக நுரை உருவாகிறது.   \n",
            "\n",
            "  class_label                                 cleaned_transcript  \n",
            "0          AI      சோப்பின் மணம் புத்துணர்ச்சியூட்டும் வகையில் .  \n",
            "1          AI              தோலை நன்கு சுத்தம் செய்ய சிறப்பானது .  \n",
            "2          AI              இதைப் பயன்படுத்திய , தோல் மென்மையாக .  \n",
            "3          AI  சோப்பில் இயற்கையான மூலப்பொருட்கள் பயன்படுத்தப்...  \n",
            "4          AI           சிறிது சோப்பு போதும் , நுரை உருவாகிறது .  \n",
            "Label encoder saved to tamil_label_encoder.pkl\n",
            "TF-IDF and Count Vectorizers saved successfully.\n",
            "Training with TF-IDF features...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.5120 - loss: 1.2766 - val_accuracy: 0.4691 - val_loss: 0.6854\n",
            "Epoch 2/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6637 - loss: 0.7851 - val_accuracy: 0.4691 - val_loss: 0.6884\n",
            "Epoch 3/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7558 - loss: 0.5879 - val_accuracy: 0.4691 - val_loss: 0.6986\n",
            "Epoch 4/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7723 - loss: 0.4836 - val_accuracy: 0.4691 - val_loss: 0.7022\n",
            "Epoch 5/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8248 - loss: 0.4265 - val_accuracy: 0.4691 - val_loss: 0.6999\n",
            "Epoch 6/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8326 - loss: 0.3831 - val_accuracy: 0.4691 - val_loss: 0.7066\n",
            "Epoch 7/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8807 - loss: 0.2937 - val_accuracy: 0.4691 - val_loss: 0.6979\n",
            "Epoch 8/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8674 - loss: 0.2973 - val_accuracy: 0.4877 - val_loss: 0.6792\n",
            "Epoch 9/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8777 - loss: 0.2568 - val_accuracy: 0.4938 - val_loss: 0.6632\n",
            "Epoch 10/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9019 - loss: 0.2288 - val_accuracy: 0.5247 - val_loss: 0.6489\n",
            "Epoch 11/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9163 - loss: 0.2245 - val_accuracy: 0.5556 - val_loss: 0.6300\n",
            "Epoch 12/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9331 - loss: 0.2064 - val_accuracy: 0.6667 - val_loss: 0.5922\n",
            "Epoch 13/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9338 - loss: 0.1837 - val_accuracy: 0.7099 - val_loss: 0.5652\n",
            "Epoch 14/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9274 - loss: 0.1843 - val_accuracy: 0.7222 - val_loss: 0.5364\n",
            "Epoch 15/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9359 - loss: 0.1617 - val_accuracy: 0.7284 - val_loss: 0.5307\n",
            "Epoch 16/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9367 - loss: 0.1852 - val_accuracy: 0.7469 - val_loss: 0.5178\n",
            "Epoch 17/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9370 - loss: 0.1409 - val_accuracy: 0.7531 - val_loss: 0.4951\n",
            "Epoch 18/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9503 - loss: 0.1338 - val_accuracy: 0.7531 - val_loss: 0.4841\n",
            "Epoch 19/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9486 - loss: 0.1421 - val_accuracy: 0.7531 - val_loss: 0.4671\n",
            "Epoch 20/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9557 - loss: 0.1196 - val_accuracy: 0.7593 - val_loss: 0.4490\n",
            "Epoch 21/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9661 - loss: 0.1092 - val_accuracy: 0.7963 - val_loss: 0.4270\n",
            "Epoch 22/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9790 - loss: 0.0799 - val_accuracy: 0.7778 - val_loss: 0.4328\n",
            "Epoch 23/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9662 - loss: 0.0859 - val_accuracy: 0.7840 - val_loss: 0.4436\n",
            "Epoch 24/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9550 - loss: 0.0926 - val_accuracy: 0.7963 - val_loss: 0.4300\n",
            "Epoch 25/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9643 - loss: 0.0902 - val_accuracy: 0.8025 - val_loss: 0.4321\n",
            "Epoch 26/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9726 - loss: 0.0793 - val_accuracy: 0.7963 - val_loss: 0.4508\n",
            "Epoch 27/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9453 - loss: 0.1073 - val_accuracy: 0.7778 - val_loss: 0.4736\n",
            "Epoch 28/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9572 - loss: 0.1036 - val_accuracy: 0.7716 - val_loss: 0.4941\n",
            "Epoch 29/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9697 - loss: 0.0739 - val_accuracy: 0.7901 - val_loss: 0.4873\n",
            "Epoch 30/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9790 - loss: 0.0643 - val_accuracy: 0.7840 - val_loss: 0.4970\n",
            "Epoch 31/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9792 - loss: 0.0617 - val_accuracy: 0.7901 - val_loss: 0.5024\n",
            "Epoch 32/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0655 - val_accuracy: 0.7840 - val_loss: 0.5127\n",
            "Epoch 33/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9630 - loss: 0.0919 - val_accuracy: 0.7778 - val_loss: 0.5502\n",
            "Epoch 34/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9698 - loss: 0.0709 - val_accuracy: 0.7778 - val_loss: 0.5563\n",
            "Epoch 35/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9692 - loss: 0.0683 - val_accuracy: 0.7840 - val_loss: 0.5793\n",
            "Epoch 36/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9741 - loss: 0.0679 - val_accuracy: 0.7963 - val_loss: 0.5758\n",
            "Epoch 37/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9631 - loss: 0.0804 - val_accuracy: 0.7778 - val_loss: 0.5863\n",
            "Epoch 38/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9826 - loss: 0.0543 - val_accuracy: 0.7778 - val_loss: 0.5767\n",
            "Epoch 39/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9826 - loss: 0.0467 - val_accuracy: 0.7963 - val_loss: 0.5530\n",
            "Epoch 40/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9793 - loss: 0.0705 - val_accuracy: 0.8025 - val_loss: 0.5493\n",
            "Epoch 41/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9789 - loss: 0.0604 - val_accuracy: 0.7963 - val_loss: 0.5439\n",
            "Epoch 42/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9750 - loss: 0.0763 - val_accuracy: 0.8025 - val_loss: 0.5400\n",
            "Epoch 43/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9719 - loss: 0.0607 - val_accuracy: 0.7840 - val_loss: 0.5459\n",
            "Epoch 44/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0948 - val_accuracy: 0.7901 - val_loss: 0.5601\n",
            "Epoch 45/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9727 - loss: 0.0649 - val_accuracy: 0.7840 - val_loss: 0.5985\n",
            "Epoch 46/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9641 - loss: 0.0787 - val_accuracy: 0.7963 - val_loss: 0.5976\n",
            "Epoch 47/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9768 - loss: 0.0555 - val_accuracy: 0.7963 - val_loss: 0.6062\n",
            "Epoch 48/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9846 - loss: 0.0455 - val_accuracy: 0.7963 - val_loss: 0.6210\n",
            "Epoch 49/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9743 - loss: 0.0689 - val_accuracy: 0.8025 - val_loss: 0.6146\n",
            "Epoch 50/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9824 - loss: 0.0480 - val_accuracy: 0.7963 - val_loss: 0.6014\n",
            "Epoch 51/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9722 - loss: 0.0715 - val_accuracy: 0.8025 - val_loss: 0.6048\n",
            "Epoch 52/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9586 - loss: 0.0818 - val_accuracy: 0.7901 - val_loss: 0.6241\n",
            "Epoch 53/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9825 - loss: 0.0585 - val_accuracy: 0.8025 - val_loss: 0.6321\n",
            "Epoch 54/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9742 - loss: 0.0653 - val_accuracy: 0.8025 - val_loss: 0.6125\n",
            "Epoch 55/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9764 - loss: 0.0845 - val_accuracy: 0.8148 - val_loss: 0.6113\n",
            "Epoch 56/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9665 - loss: 0.0704 - val_accuracy: 0.8148 - val_loss: 0.5928\n",
            "Epoch 57/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9824 - loss: 0.0628 - val_accuracy: 0.8210 - val_loss: 0.5981\n",
            "Epoch 58/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9910 - loss: 0.0422 - val_accuracy: 0.8148 - val_loss: 0.6152\n",
            "Epoch 59/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9741 - loss: 0.0632 - val_accuracy: 0.7963 - val_loss: 0.6082\n",
            "Epoch 60/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9868 - loss: 0.0493 - val_accuracy: 0.8086 - val_loss: 0.5811\n",
            "Epoch 61/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9498 - loss: 0.1022 - val_accuracy: 0.8086 - val_loss: 0.5695\n",
            "Epoch 62/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9837 - loss: 0.0392 - val_accuracy: 0.8086 - val_loss: 0.5957\n",
            "Epoch 63/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9751 - loss: 0.0646 - val_accuracy: 0.7963 - val_loss: 0.5913\n",
            "Epoch 64/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9715 - loss: 0.0579 - val_accuracy: 0.7840 - val_loss: 0.5988\n",
            "Epoch 65/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9702 - loss: 0.0722 - val_accuracy: 0.7963 - val_loss: 0.6103\n",
            "Epoch 66/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9723 - loss: 0.0613 - val_accuracy: 0.7901 - val_loss: 0.6159\n",
            "Epoch 67/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9804 - loss: 0.0631 - val_accuracy: 0.7963 - val_loss: 0.6182\n",
            "Epoch 68/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9882 - loss: 0.0362 - val_accuracy: 0.8025 - val_loss: 0.6365\n",
            "Epoch 69/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9873 - loss: 0.0501 - val_accuracy: 0.7963 - val_loss: 0.6409\n",
            "Epoch 70/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9821 - loss: 0.0461 - val_accuracy: 0.7840 - val_loss: 0.6353\n",
            "Epoch 71/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9777 - loss: 0.0447 - val_accuracy: 0.7840 - val_loss: 0.6401\n",
            "Epoch 72/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9711 - loss: 0.0826 - val_accuracy: 0.8025 - val_loss: 0.6431\n",
            "Epoch 73/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9835 - loss: 0.0580 - val_accuracy: 0.7901 - val_loss: 0.6538\n",
            "Epoch 74/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9945 - loss: 0.0307 - val_accuracy: 0.7901 - val_loss: 0.6542\n",
            "Epoch 75/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9871 - loss: 0.0436 - val_accuracy: 0.7901 - val_loss: 0.6386\n",
            "Epoch 76/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9747 - loss: 0.0636 - val_accuracy: 0.7901 - val_loss: 0.6287\n",
            "Epoch 77/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9797 - loss: 0.0574 - val_accuracy: 0.7963 - val_loss: 0.6903\n",
            "Epoch 78/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9830 - loss: 0.0575 - val_accuracy: 0.7901 - val_loss: 0.6977\n",
            "Epoch 79/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9822 - loss: 0.0433 - val_accuracy: 0.7901 - val_loss: 0.6589\n",
            "Epoch 80/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9830 - loss: 0.0415 - val_accuracy: 0.7901 - val_loss: 0.6318\n",
            "Epoch 81/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9816 - loss: 0.0456 - val_accuracy: 0.7778 - val_loss: 0.6214\n",
            "Epoch 82/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9813 - loss: 0.0505 - val_accuracy: 0.7963 - val_loss: 0.5956\n",
            "Epoch 83/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9789 - loss: 0.0488 - val_accuracy: 0.8148 - val_loss: 0.5907\n",
            "Epoch 84/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9749 - loss: 0.0607 - val_accuracy: 0.8025 - val_loss: 0.5962\n",
            "Epoch 85/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9818 - loss: 0.0459 - val_accuracy: 0.8086 - val_loss: 0.6099\n",
            "Epoch 86/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9806 - loss: 0.0463 - val_accuracy: 0.8025 - val_loss: 0.6207\n",
            "Epoch 87/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9860 - loss: 0.0365 - val_accuracy: 0.8086 - val_loss: 0.6159\n",
            "Epoch 88/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9824 - loss: 0.0467 - val_accuracy: 0.8025 - val_loss: 0.6086\n",
            "Epoch 89/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9933 - loss: 0.0240 - val_accuracy: 0.8086 - val_loss: 0.5912\n",
            "Epoch 90/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9918 - loss: 0.0288 - val_accuracy: 0.8025 - val_loss: 0.5801\n",
            "Epoch 91/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9837 - loss: 0.0585 - val_accuracy: 0.8210 - val_loss: 0.5821\n",
            "Epoch 92/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9867 - loss: 0.0329 - val_accuracy: 0.8148 - val_loss: 0.6035\n",
            "Epoch 93/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9801 - loss: 0.0591 - val_accuracy: 0.8333 - val_loss: 0.5841\n",
            "Epoch 94/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9820 - loss: 0.0453 - val_accuracy: 0.8333 - val_loss: 0.5406\n",
            "Epoch 95/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9801 - loss: 0.0516 - val_accuracy: 0.8086 - val_loss: 0.5905\n",
            "Epoch 96/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9720 - loss: 0.0619 - val_accuracy: 0.8025 - val_loss: 0.5707\n",
            "Epoch 97/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9753 - loss: 0.0525 - val_accuracy: 0.7963 - val_loss: 0.5174\n",
            "Epoch 98/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9606 - loss: 0.0967 - val_accuracy: 0.7963 - val_loss: 0.5278\n",
            "Epoch 99/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9849 - loss: 0.0484 - val_accuracy: 0.8148 - val_loss: 0.5209\n",
            "Epoch 100/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9850 - loss: 0.0394 - val_accuracy: 0.8148 - val_loss: 0.5290\n",
            "TF-IDF Model Test Accuracy: 0.8148\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "TF-IDF Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          AI       0.85      0.79      0.82        86\n",
            "       HUMAN       0.78      0.84      0.81        76\n",
            "\n",
            "    accuracy                           0.81       162\n",
            "   macro avg       0.82      0.82      0.81       162\n",
            "weighted avg       0.82      0.81      0.81       162\n",
            "\n",
            "Training with Count Vectorizer features...\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.5984 - loss: 1.0336 - val_accuracy: 0.7284 - val_loss: 0.6287\n",
            "Epoch 2/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7081 - loss: 0.7503 - val_accuracy: 0.6975 - val_loss: 0.6149\n",
            "Epoch 3/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7289 - loss: 0.6784 - val_accuracy: 0.6728 - val_loss: 0.6059\n",
            "Epoch 4/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8235 - loss: 0.4807 - val_accuracy: 0.6605 - val_loss: 0.5978\n",
            "Epoch 5/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8066 - loss: 0.4302 - val_accuracy: 0.6296 - val_loss: 0.5861\n",
            "Epoch 6/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8613 - loss: 0.3843 - val_accuracy: 0.6358 - val_loss: 0.5823\n",
            "Epoch 7/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8565 - loss: 0.3382 - val_accuracy: 0.6420 - val_loss: 0.5784\n",
            "Epoch 8/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8652 - loss: 0.3233 - val_accuracy: 0.6605 - val_loss: 0.5562\n",
            "Epoch 9/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8785 - loss: 0.2897 - val_accuracy: 0.6852 - val_loss: 0.5309\n",
            "Epoch 10/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9118 - loss: 0.2154 - val_accuracy: 0.6975 - val_loss: 0.5109\n",
            "Epoch 11/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9140 - loss: 0.2564 - val_accuracy: 0.7037 - val_loss: 0.5033\n",
            "Epoch 12/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9362 - loss: 0.1675 - val_accuracy: 0.7222 - val_loss: 0.4840\n",
            "Epoch 13/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9371 - loss: 0.1498 - val_accuracy: 0.7593 - val_loss: 0.4544\n",
            "Epoch 14/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9370 - loss: 0.1602 - val_accuracy: 0.7654 - val_loss: 0.4372\n",
            "Epoch 15/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9372 - loss: 0.1526 - val_accuracy: 0.7778 - val_loss: 0.4291\n",
            "Epoch 16/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9492 - loss: 0.1536 - val_accuracy: 0.7901 - val_loss: 0.4081\n",
            "Epoch 17/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9147 - loss: 0.1953 - val_accuracy: 0.7840 - val_loss: 0.4133\n",
            "Epoch 18/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9152 - loss: 0.2022 - val_accuracy: 0.8025 - val_loss: 0.3966\n",
            "Epoch 19/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9518 - loss: 0.1206 - val_accuracy: 0.7901 - val_loss: 0.3977\n",
            "Epoch 20/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9333 - loss: 0.1487 - val_accuracy: 0.7901 - val_loss: 0.3944\n",
            "Epoch 21/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9397 - loss: 0.1611 - val_accuracy: 0.8086 - val_loss: 0.3803\n",
            "Epoch 22/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9539 - loss: 0.1138 - val_accuracy: 0.8148 - val_loss: 0.3690\n",
            "Epoch 23/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9518 - loss: 0.1229 - val_accuracy: 0.8333 - val_loss: 0.3618\n",
            "Epoch 24/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9458 - loss: 0.1401 - val_accuracy: 0.8210 - val_loss: 0.3628\n",
            "Epoch 25/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9718 - loss: 0.0944 - val_accuracy: 0.8457 - val_loss: 0.3519\n",
            "Epoch 26/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9551 - loss: 0.1067 - val_accuracy: 0.8333 - val_loss: 0.3459\n",
            "Epoch 27/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9646 - loss: 0.0959 - val_accuracy: 0.8272 - val_loss: 0.3731\n",
            "Epoch 28/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9644 - loss: 0.0937 - val_accuracy: 0.8457 - val_loss: 0.3668\n",
            "Epoch 29/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9823 - loss: 0.0768 - val_accuracy: 0.8395 - val_loss: 0.3747\n",
            "Epoch 30/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9803 - loss: 0.0611 - val_accuracy: 0.8333 - val_loss: 0.3737\n",
            "Epoch 31/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9484 - loss: 0.1233 - val_accuracy: 0.8395 - val_loss: 0.3744\n",
            "Epoch 32/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9697 - loss: 0.0848 - val_accuracy: 0.8333 - val_loss: 0.3686\n",
            "Epoch 33/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9602 - loss: 0.1102 - val_accuracy: 0.8457 - val_loss: 0.3634\n",
            "Epoch 34/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9592 - loss: 0.1052 - val_accuracy: 0.8395 - val_loss: 0.3635\n",
            "Epoch 35/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9758 - loss: 0.0720 - val_accuracy: 0.8395 - val_loss: 0.3644\n",
            "Epoch 36/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9556 - loss: 0.1066 - val_accuracy: 0.8519 - val_loss: 0.3851\n",
            "Epoch 37/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9798 - loss: 0.0789 - val_accuracy: 0.8457 - val_loss: 0.3917\n",
            "Epoch 38/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9715 - loss: 0.0831 - val_accuracy: 0.8580 - val_loss: 0.3956\n",
            "Epoch 39/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9565 - loss: 0.1217 - val_accuracy: 0.8457 - val_loss: 0.3986\n",
            "Epoch 40/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9783 - loss: 0.0724 - val_accuracy: 0.8457 - val_loss: 0.4021\n",
            "Epoch 41/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9738 - loss: 0.0653 - val_accuracy: 0.8457 - val_loss: 0.4004\n",
            "Epoch 42/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9705 - loss: 0.0855 - val_accuracy: 0.8457 - val_loss: 0.4108\n",
            "Epoch 43/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9744 - loss: 0.0738 - val_accuracy: 0.8457 - val_loss: 0.4051\n",
            "Epoch 44/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9697 - loss: 0.0754 - val_accuracy: 0.8457 - val_loss: 0.4016\n",
            "Epoch 45/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9723 - loss: 0.0826 - val_accuracy: 0.8333 - val_loss: 0.3907\n",
            "Epoch 46/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9676 - loss: 0.0895 - val_accuracy: 0.8210 - val_loss: 0.4006\n",
            "Epoch 47/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9623 - loss: 0.1044 - val_accuracy: 0.8025 - val_loss: 0.4185\n",
            "Epoch 48/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9659 - loss: 0.0913 - val_accuracy: 0.8272 - val_loss: 0.4333\n",
            "Epoch 49/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9647 - loss: 0.0696 - val_accuracy: 0.8272 - val_loss: 0.4427\n",
            "Epoch 50/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9601 - loss: 0.0858 - val_accuracy: 0.8148 - val_loss: 0.4481\n",
            "Epoch 51/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9710 - loss: 0.0837 - val_accuracy: 0.8148 - val_loss: 0.4364\n",
            "Epoch 52/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9632 - loss: 0.0925 - val_accuracy: 0.8086 - val_loss: 0.4390\n",
            "Epoch 53/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9680 - loss: 0.0833 - val_accuracy: 0.8148 - val_loss: 0.4273\n",
            "Epoch 54/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9572 - loss: 0.1308 - val_accuracy: 0.8210 - val_loss: 0.4225\n",
            "Epoch 55/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9807 - loss: 0.0607 - val_accuracy: 0.8210 - val_loss: 0.4197\n",
            "Epoch 56/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9668 - loss: 0.0730 - val_accuracy: 0.8148 - val_loss: 0.4323\n",
            "Epoch 57/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9762 - loss: 0.0721 - val_accuracy: 0.7963 - val_loss: 0.4443\n",
            "Epoch 58/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9685 - loss: 0.0902 - val_accuracy: 0.8272 - val_loss: 0.4440\n",
            "Epoch 59/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9666 - loss: 0.1035 - val_accuracy: 0.8395 - val_loss: 0.4369\n",
            "Epoch 60/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9826 - loss: 0.0628 - val_accuracy: 0.8457 - val_loss: 0.4227\n",
            "Epoch 61/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9832 - loss: 0.0696 - val_accuracy: 0.8395 - val_loss: 0.4224\n",
            "Epoch 62/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9728 - loss: 0.0609 - val_accuracy: 0.8333 - val_loss: 0.4173\n",
            "Epoch 63/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9857 - loss: 0.0542 - val_accuracy: 0.8272 - val_loss: 0.4135\n",
            "Epoch 64/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9747 - loss: 0.0579 - val_accuracy: 0.8272 - val_loss: 0.4091\n",
            "Epoch 65/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9594 - loss: 0.0915 - val_accuracy: 0.8210 - val_loss: 0.4303\n",
            "Epoch 66/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9642 - loss: 0.0853 - val_accuracy: 0.8333 - val_loss: 0.4323\n",
            "Epoch 67/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9802 - loss: 0.0683 - val_accuracy: 0.8333 - val_loss: 0.4206\n",
            "Epoch 68/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9790 - loss: 0.0602 - val_accuracy: 0.8333 - val_loss: 0.4211\n",
            "Epoch 69/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9842 - loss: 0.0419 - val_accuracy: 0.8333 - val_loss: 0.4299\n",
            "Epoch 70/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9846 - loss: 0.0421 - val_accuracy: 0.8272 - val_loss: 0.4346\n",
            "Epoch 71/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9731 - loss: 0.0629 - val_accuracy: 0.8333 - val_loss: 0.4364\n",
            "Epoch 72/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9718 - loss: 0.0613 - val_accuracy: 0.8272 - val_loss: 0.4390\n",
            "Epoch 73/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9730 - loss: 0.0562 - val_accuracy: 0.8210 - val_loss: 0.4386\n",
            "Epoch 74/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9629 - loss: 0.0850 - val_accuracy: 0.8148 - val_loss: 0.4652\n",
            "Epoch 75/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9718 - loss: 0.0903 - val_accuracy: 0.8272 - val_loss: 0.4905\n",
            "Epoch 76/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9695 - loss: 0.0762 - val_accuracy: 0.8272 - val_loss: 0.4900\n",
            "Epoch 77/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9718 - loss: 0.0698 - val_accuracy: 0.8210 - val_loss: 0.4915\n",
            "Epoch 78/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9904 - loss: 0.0435 - val_accuracy: 0.8210 - val_loss: 0.4855\n",
            "Epoch 79/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9809 - loss: 0.0560 - val_accuracy: 0.8086 - val_loss: 0.4713\n",
            "Epoch 80/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9795 - loss: 0.0455 - val_accuracy: 0.8272 - val_loss: 0.4765\n",
            "Epoch 81/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9793 - loss: 0.0641 - val_accuracy: 0.8333 - val_loss: 0.4829\n",
            "Epoch 82/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9837 - loss: 0.0481 - val_accuracy: 0.8272 - val_loss: 0.4798\n",
            "Epoch 83/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9770 - loss: 0.0547 - val_accuracy: 0.8148 - val_loss: 0.4786\n",
            "Epoch 84/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9633 - loss: 0.0737 - val_accuracy: 0.8148 - val_loss: 0.4605\n",
            "Epoch 85/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9867 - loss: 0.0488 - val_accuracy: 0.8148 - val_loss: 0.4424\n",
            "Epoch 86/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9848 - loss: 0.0588 - val_accuracy: 0.8272 - val_loss: 0.4503\n",
            "Epoch 87/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9798 - loss: 0.0523 - val_accuracy: 0.8148 - val_loss: 0.4581\n",
            "Epoch 88/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9773 - loss: 0.0611 - val_accuracy: 0.8148 - val_loss: 0.4653\n",
            "Epoch 89/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9676 - loss: 0.0668 - val_accuracy: 0.8025 - val_loss: 0.4696\n",
            "Epoch 90/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9786 - loss: 0.0520 - val_accuracy: 0.8148 - val_loss: 0.4619\n",
            "Epoch 91/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9702 - loss: 0.0692 - val_accuracy: 0.8086 - val_loss: 0.4631\n",
            "Epoch 92/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9842 - loss: 0.0496 - val_accuracy: 0.8025 - val_loss: 0.4674\n",
            "Epoch 93/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9860 - loss: 0.0451 - val_accuracy: 0.8210 - val_loss: 0.4702\n",
            "Epoch 94/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9909 - loss: 0.0338 - val_accuracy: 0.8272 - val_loss: 0.4728\n",
            "Epoch 95/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9665 - loss: 0.0796 - val_accuracy: 0.8148 - val_loss: 0.4726\n",
            "Epoch 96/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9766 - loss: 0.0500 - val_accuracy: 0.8272 - val_loss: 0.4759\n",
            "Epoch 97/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9715 - loss: 0.0627 - val_accuracy: 0.8210 - val_loss: 0.4825\n",
            "Epoch 98/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9816 - loss: 0.0582 - val_accuracy: 0.8333 - val_loss: 0.4758\n",
            "Epoch 99/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9868 - loss: 0.0436 - val_accuracy: 0.8333 - val_loss: 0.4860\n",
            "Epoch 100/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9781 - loss: 0.0558 - val_accuracy: 0.8272 - val_loss: 0.4919\n",
            "Count Vectorizer Model Test Accuracy: 0.8272\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Count Vectorizer Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          AI       0.85      0.83      0.84        86\n",
            "       HUMAN       0.81      0.83      0.82        76\n",
            "\n",
            "    accuracy                           0.83       162\n",
            "   macro avg       0.83      0.83      0.83       162\n",
            "weighted avg       0.83      0.83      0.83       162\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report\n",
        "from indicnlp.tokenize import indic_tokenize\n",
        "from indicnlp.normalize.indic_normalize import IndicNormalizerFactory\n",
        "import advertools as adv\n",
        "import pickle\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "file_path = \"/content/tam_training_data_hum_ai (1).csv\"\n",
        "dataset_df = pd.read_csv(file_path)\n",
        "dataset_df.columns = ['id', 'transcript', 'class_label']\n",
        "print(dataset_df.head())\n",
        "\n",
        "stopwords = list(sorted(adv.stopwords['tamil']))\n",
        "\n",
        "def preprocess_tamil_text(text):\n",
        "    \"\"\"Preprocess Tamil text by normalizing, tokenizing, and removing stopwords.\"\"\"\n",
        "    normalizer_factory = IndicNormalizerFactory()\n",
        "    normalizer = normalizer_factory.get_normalizer(\"ta\")\n",
        "    text = normalizer.normalize(text)\n",
        "    tokens = list(indic_tokenize.trivial_tokenize(text, lang=\"ta\"))\n",
        "    tokens = [token for token in tokens if token not in stopwords]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "dataset_df['cleaned_transcript'] = dataset_df['transcript'].apply(preprocess_tamil_text)\n",
        "print(dataset_df.head())\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "dataset_df['encoded_label'] = label_encoder.fit_transform(dataset_df['class_label'])\n",
        "\n",
        "label_encoder_path = \"tamil_label_encoder.pkl\"\n",
        "with open(label_encoder_path, \"wb\") as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "print(f\"Label encoder saved to {label_encoder_path}\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    dataset_df['cleaned_transcript'], dataset_df['encoded_label'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train).toarray()\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test).toarray()\n",
        "\n",
        "count_vectorizer = CountVectorizer(max_features=5000)\n",
        "X_train_count = count_vectorizer.fit_transform(X_train).toarray()\n",
        "X_test_count = count_vectorizer.transform(X_test).toarray()\n",
        "\n",
        "with open(\"tfidf_vectorizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tfidf_vectorizer, f)\n",
        "\n",
        "with open(\"count_vectorizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(count_vectorizer, f)\n",
        "\n",
        "print(\"TF-IDF and Count Vectorizers saved successfully.\")\n",
        "\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "\n",
        "def build_model(input_dim, output_dim):\n",
        "    model = Sequential([\n",
        "        Dense(256, input_dim=input_dim, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(output_dim, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "print(\"Training with TF-IDF features...\")\n",
        "model_tfidf = build_model(X_train_tfidf.shape[1], len(label_encoder.classes_))\n",
        "history_tfidf = model_tfidf.fit(\n",
        "    X_train_tfidf, y_train_cat,\n",
        "    validation_data=(X_test_tfidf, y_test_cat),\n",
        "    epochs=100, batch_size=32, verbose=1\n",
        ")\n",
        "\n",
        "loss_tfidf, accuracy_tfidf = model_tfidf.evaluate(X_test_tfidf, y_test_cat, verbose=0)\n",
        "print(f\"TF-IDF Model Test Accuracy: {accuracy_tfidf:.4f}\")\n",
        "\n",
        "y_pred_tfidf = model_tfidf.predict(X_test_tfidf)\n",
        "y_pred_tfidf_labels = np.argmax(y_pred_tfidf, axis=1)\n",
        "print(\"TF-IDF Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_tfidf_labels, target_names=label_encoder.classes_))\n",
        "\n",
        "print(\"Training with Count Vectorizer features...\")\n",
        "model_count = build_model(X_train_count.shape[1], len(label_encoder.classes_))\n",
        "history_count = model_count.fit(\n",
        "    X_train_count, y_train_cat,\n",
        "    validation_data=(X_test_count, y_test_cat),\n",
        "    epochs=100, batch_size=32, verbose=1\n",
        ")\n",
        "\n",
        "loss_count, accuracy_count = model_count.evaluate(X_test_count, y_test_cat, verbose=0)\n",
        "print(f\"Count Vectorizer Model Test Accuracy: {accuracy_count:.4f}\")\n",
        "\n",
        "y_pred_count = model_count.predict(X_test_count)\n",
        "y_pred_count_labels = np.argmax(y_pred_count, axis=1)\n",
        "print(\"Count Vectorizer Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_count_labels, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JMU90AvJ5vh"
      },
      "source": [
        "Malayalam CountVectorizer and TFIDFVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4wwQDbEF479",
        "outputId": "7bc9e54d-3985-49e2-f261-882c9a26ae4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: advertools in /usr/local/lib/python3.11/dist-packages (0.16.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from advertools) (2.2.2)\n",
            "Requirement already satisfied: pyasn1>=0.4 in /usr/local/lib/python3.11/dist-packages (from advertools) (0.6.1)\n",
            "Requirement already satisfied: scrapy>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from advertools) (2.12.0)\n",
            "Requirement already satisfied: twython>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from advertools) (3.9.1)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from advertools) (17.0.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.0->advertools) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.0->advertools) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.0->advertools) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: Twisted>=21.7.0 in /usr/local/lib/python3.11/dist-packages (from scrapy>=2.5.0->advertools) (24.11.0)\n",
            "Requirement already satisfied: cryptography>=37.0.0 in /usr/local/lib/python3.11/dist-packages (from scrapy>=2.5.0->advertools) (43.0.3)\n",
            "Requirement already satisfied: cssselect>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from scrapy>=2.5.0->advertools) (1.2.0)\n",
            "Requirement already satisfied: itemloaders>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from scrapy>=2.5.0->advertools) (1.3.2)\n",
            "Requirement already satisfied: parsel>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from scrapy>=2.5.0->advertools) (1.10.0)\n",
            "Requirement already satisfied: pyOpenSSL>=22.0.0 in /usr/local/lib/python3.11/dist-packages (from scrapy>=2.5.0->advertools) (24.2.1)\n",
            "Requirement already satisfied: queuelib>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from scrapy>=2.5.0->advertools) (1.7.0)\n",
            "Requirement already satisfied: service-identity>=18.1.0 in /usr/local/lib/python3.11/dist-packages (from scrapy>=2.5.0->advertools) (24.2.0)\n",
            "Requirement already satisfied: w3lib>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from scrapy>=2.5.0->advertools) (2.3.1)\n",
            "Requirement already satisfied: zope.interface>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from scrapy>=2.5.0->advertools) (7.2)\n",
            "Requirement already satisfied: protego>=0.1.15 in /usr/local/lib/python3.11/dist-packages (from scrapy>=2.5.0->advertools) (0.4.0)\n",
            "Requirement already satisfied: itemadapter>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from scrapy>=2.5.0->advertools) (0.10.0)\n",
            "Requirement already satisfied: tldextract in /usr/local/lib/python3.11/dist-packages (from scrapy>=2.5.0->advertools) (5.1.3)\n",
            "Requirement already satisfied: lxml>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from scrapy>=2.5.0->advertools) (5.3.0)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from scrapy>=2.5.0->advertools) (0.7.1)\n",
            "Requirement already satisfied: PyDispatcher>=2.0.5 in /usr/local/lib/python3.11/dist-packages (from scrapy>=2.5.0->advertools) (2.0.7)\n",
            "Requirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from twython>=3.8.0->advertools) (1.3.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=37.0.0->scrapy>=2.5.0->advertools) (1.17.1)\n",
            "Requirement already satisfied: jmespath>=0.9.5 in /usr/local/lib/python3.11/dist-packages (from itemloaders>=1.0.1->scrapy>=2.5.0->advertools) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.0->advertools) (1.17.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.4.0->twython>=3.8.0->advertools) (3.2.2)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from service-identity>=18.1.0->scrapy>=2.5.0->advertools) (24.3.0)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.11/dist-packages (from service-identity>=18.1.0->scrapy>=2.5.0->advertools) (0.4.1)\n",
            "Requirement already satisfied: automat>=24.8.0 in /usr/local/lib/python3.11/dist-packages (from Twisted>=21.7.0->scrapy>=2.5.0->advertools) (24.8.1)\n",
            "Requirement already satisfied: constantly>=15.1 in /usr/local/lib/python3.11/dist-packages (from Twisted>=21.7.0->scrapy>=2.5.0->advertools) (23.10.4)\n",
            "Requirement already satisfied: hyperlink>=17.1.1 in /usr/local/lib/python3.11/dist-packages (from Twisted>=21.7.0->scrapy>=2.5.0->advertools) (21.0.0)\n",
            "Requirement already satisfied: incremental>=24.7.0 in /usr/local/lib/python3.11/dist-packages (from Twisted>=21.7.0->scrapy>=2.5.0->advertools) (24.7.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from zope.interface>=5.1.0->scrapy>=2.5.0->advertools) (75.1.0)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.11/dist-packages (from tldextract->scrapy>=2.5.0->advertools) (2.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=37.0.0->scrapy>=2.5.0->advertools) (2.22)\n",
            "                id                                         transcript  \\\n",
            "0  MAL_HUAI_TR_001  ഞാൻ കുറച്ച് കാലമായി മുച്ചട്ച്ചിൻ്റെ ഫേസ് വാഷ് ...   \n",
            "1  MAL_HUAI_TR_002           ഈ ഫേസ് വാഷ് തണുപ്പ് വെതറിലും ഉപയോഗിക്കാം   \n",
            "2  MAL_HUAI_TR_003  അണ്ണാ എനിക്ക് 14 വയസ് ആയ തേയോളു എനിക്ക് സ്കിൻക...   \n",
            "3  MAL_HUAI_TR_004  ബ്രോ ഇതെല്ലം യൂസ്  ആക്കീട്ട് നൈറ്റ് പിന്നെ വേറ...   \n",
            "4  MAL_HUAI_TR_005    ഇത് ഫേസ് വാഷ് ഡെയിലി ചെയ്താ സ്കിൻകെയറിന് നല്ലതാ   \n",
            "\n",
            "  class_label  \n",
            "0       HUMAN  \n",
            "1       HUMAN  \n",
            "2       HUMAN  \n",
            "3       HUMAN  \n",
            "4       HUMAN  \n",
            "                id                                         transcript  \\\n",
            "0  MAL_HUAI_TR_001  ഞാൻ കുറച്ച് കാലമായി മുച്ചട്ച്ചിൻ്റെ ഫേസ് വാഷ് ...   \n",
            "1  MAL_HUAI_TR_002           ഈ ഫേസ് വാഷ് തണുപ്പ് വെതറിലും ഉപയോഗിക്കാം   \n",
            "2  MAL_HUAI_TR_003  അണ്ണാ എനിക്ക് 14 വയസ് ആയ തേയോളു എനിക്ക് സ്കിൻക...   \n",
            "3  MAL_HUAI_TR_004  ബ്രോ ഇതെല്ലം യൂസ്  ആക്കീട്ട് നൈറ്റ് പിന്നെ വേറ...   \n",
            "4  MAL_HUAI_TR_005    ഇത് ഫേസ് വാഷ് ഡെയിലി ചെയ്താ സ്കിൻകെയറിന് നല്ലതാ   \n",
            "\n",
            "  class_label                                 cleaned_transcript  \n",
            "0       HUMAN  ഞാൻ കുറച്ച് കാലമായി മുച്ചട്ച്ചിൻ്റെ ഫേസ് വാഷ് ...  \n",
            "1       HUMAN           ഈ ഫേസ് വാഷ് തണുപ്പ് വെതറിലും ഉപയോഗിക്കാം  \n",
            "2       HUMAN  അണ്ണാ എനിക്ക് 14 വയസ് ആയ തേയോളു എനിക്ക് സ്കിൻക...  \n",
            "3       HUMAN  ബ്രോ ഇതെല്ലം യൂസ് ആക്കീട്ട് നൈറ്റ് പിന്നെ വേറെ...  \n",
            "4       HUMAN        ഫേസ് വാഷ് ഡെയിലി ചെയ്താ സ്കിൻകെയറിന് നല്ലതാ  \n",
            "Label encoder saved to malayalam_label_encoder.pkl\n",
            "TF-IDF and Count Vectorizers saved successfully.\n",
            "Training with TF-IDF features...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.5010 - loss: 1.3412 - val_accuracy: 0.5125 - val_loss: 0.6847\n",
            "Epoch 2/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7138 - loss: 0.6772 - val_accuracy: 0.5000 - val_loss: 0.6795\n",
            "Epoch 3/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7542 - loss: 0.5240 - val_accuracy: 0.5000 - val_loss: 0.6744\n",
            "Epoch 4/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8090 - loss: 0.4641 - val_accuracy: 0.5063 - val_loss: 0.6684\n",
            "Epoch 5/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8941 - loss: 0.2533 - val_accuracy: 0.5063 - val_loss: 0.6676\n",
            "Epoch 6/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9044 - loss: 0.2541 - val_accuracy: 0.5063 - val_loss: 0.6728\n",
            "Epoch 7/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9266 - loss: 0.1726 - val_accuracy: 0.5063 - val_loss: 0.6771\n",
            "Epoch 8/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9212 - loss: 0.1643 - val_accuracy: 0.5250 - val_loss: 0.6656\n",
            "Epoch 9/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9637 - loss: 0.1146 - val_accuracy: 0.5500 - val_loss: 0.6601\n",
            "Epoch 10/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9862 - loss: 0.0704 - val_accuracy: 0.5813 - val_loss: 0.6481\n",
            "Epoch 11/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9681 - loss: 0.0773 - val_accuracy: 0.6000 - val_loss: 0.6430\n",
            "Epoch 12/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9687 - loss: 0.0760 - val_accuracy: 0.6125 - val_loss: 0.6326\n",
            "Epoch 13/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9704 - loss: 0.0555 - val_accuracy: 0.6438 - val_loss: 0.6220\n",
            "Epoch 14/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9911 - loss: 0.0301 - val_accuracy: 0.6938 - val_loss: 0.6024\n",
            "Epoch 15/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9914 - loss: 0.0324 - val_accuracy: 0.7188 - val_loss: 0.5894\n",
            "Epoch 16/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9845 - loss: 0.0382 - val_accuracy: 0.7188 - val_loss: 0.5853\n",
            "Epoch 17/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9914 - loss: 0.0286 - val_accuracy: 0.7250 - val_loss: 0.5748\n",
            "Epoch 18/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9902 - loss: 0.0419 - val_accuracy: 0.7312 - val_loss: 0.5646\n",
            "Epoch 19/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9865 - loss: 0.0389 - val_accuracy: 0.7688 - val_loss: 0.5574\n",
            "Epoch 20/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9864 - loss: 0.0413 - val_accuracy: 0.7437 - val_loss: 0.5564\n",
            "Epoch 21/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9985 - loss: 0.0218 - val_accuracy: 0.7375 - val_loss: 0.5636\n",
            "Epoch 22/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9863 - loss: 0.0317 - val_accuracy: 0.7500 - val_loss: 0.5684\n",
            "Epoch 23/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9850 - loss: 0.0406 - val_accuracy: 0.7625 - val_loss: 0.5751\n",
            "Epoch 24/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9828 - loss: 0.0248 - val_accuracy: 0.7500 - val_loss: 0.5813\n",
            "Epoch 25/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9919 - loss: 0.0207 - val_accuracy: 0.7375 - val_loss: 0.6152\n",
            "Epoch 26/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9968 - loss: 0.0127 - val_accuracy: 0.7375 - val_loss: 0.6564\n",
            "Epoch 27/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9920 - loss: 0.0184 - val_accuracy: 0.7500 - val_loss: 0.6671\n",
            "Epoch 28/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9920 - loss: 0.0177 - val_accuracy: 0.7625 - val_loss: 0.6980\n",
            "Epoch 29/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9945 - loss: 0.0127 - val_accuracy: 0.7625 - val_loss: 0.7297\n",
            "Epoch 30/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9921 - loss: 0.0155 - val_accuracy: 0.7625 - val_loss: 0.7651\n",
            "Epoch 31/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9980 - loss: 0.0094 - val_accuracy: 0.7688 - val_loss: 0.7981\n",
            "Epoch 32/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0101 - val_accuracy: 0.7563 - val_loss: 0.8387\n",
            "Epoch 33/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9973 - loss: 0.0127 - val_accuracy: 0.7688 - val_loss: 0.8748\n",
            "Epoch 34/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9854 - loss: 0.0352 - val_accuracy: 0.7500 - val_loss: 0.9286\n",
            "Epoch 35/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.7437 - val_loss: 0.9698\n",
            "Epoch 36/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9877 - loss: 0.0205 - val_accuracy: 0.7563 - val_loss: 0.9969\n",
            "Epoch 37/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9945 - loss: 0.0214 - val_accuracy: 0.7437 - val_loss: 1.0182\n",
            "Epoch 38/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9959 - loss: 0.0090 - val_accuracy: 0.7437 - val_loss: 1.0610\n",
            "Epoch 39/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9880 - loss: 0.0227 - val_accuracy: 0.7625 - val_loss: 1.1134\n",
            "Epoch 40/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9919 - loss: 0.0255 - val_accuracy: 0.7500 - val_loss: 1.1378\n",
            "Epoch 41/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0089 - val_accuracy: 0.7500 - val_loss: 1.1591\n",
            "Epoch 42/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9941 - loss: 0.0116 - val_accuracy: 0.7437 - val_loss: 1.1751\n",
            "Epoch 43/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0052 - val_accuracy: 0.7375 - val_loss: 1.2015\n",
            "Epoch 44/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0021 - val_accuracy: 0.7312 - val_loss: 1.2171\n",
            "Epoch 45/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9971 - loss: 0.0112 - val_accuracy: 0.7312 - val_loss: 1.2501\n",
            "Epoch 46/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.7312 - val_loss: 1.2627\n",
            "Epoch 47/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9946 - loss: 0.0077 - val_accuracy: 0.7375 - val_loss: 1.2682\n",
            "Epoch 48/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.7375 - val_loss: 1.2667\n",
            "Epoch 49/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0135 - val_accuracy: 0.7312 - val_loss: 1.3084\n",
            "Epoch 50/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.7437 - val_loss: 1.3433\n",
            "Epoch 51/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 0.7375 - val_loss: 1.3731\n",
            "Epoch 52/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0068 - val_accuracy: 0.7437 - val_loss: 1.3633\n",
            "Epoch 53/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9953 - loss: 0.0068 - val_accuracy: 0.7312 - val_loss: 1.3665\n",
            "Epoch 54/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.7312 - val_loss: 1.3695\n",
            "Epoch 55/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.7312 - val_loss: 1.3882\n",
            "Epoch 56/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0169 - val_accuracy: 0.7312 - val_loss: 1.4217\n",
            "Epoch 57/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0034 - val_accuracy: 0.7375 - val_loss: 1.4033\n",
            "Epoch 58/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9980 - loss: 0.0085 - val_accuracy: 0.7375 - val_loss: 1.3969\n",
            "Epoch 59/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9935 - loss: 0.0122 - val_accuracy: 0.7188 - val_loss: 1.4309\n",
            "Epoch 60/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0043 - val_accuracy: 0.7250 - val_loss: 1.4735\n",
            "Epoch 61/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9970 - loss: 0.0077 - val_accuracy: 0.7312 - val_loss: 1.4910\n",
            "Epoch 62/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0063 - val_accuracy: 0.7312 - val_loss: 1.4931\n",
            "Epoch 63/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.7312 - val_loss: 1.4905\n",
            "Epoch 64/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 0.7312 - val_loss: 1.4959\n",
            "Epoch 65/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9950 - loss: 0.0055 - val_accuracy: 0.7437 - val_loss: 1.5017\n",
            "Epoch 66/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0182 - val_accuracy: 0.7500 - val_loss: 1.4977\n",
            "Epoch 67/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9925 - loss: 0.0276 - val_accuracy: 0.7437 - val_loss: 1.4695\n",
            "Epoch 68/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9930 - loss: 0.0185 - val_accuracy: 0.7437 - val_loss: 1.4886\n",
            "Epoch 69/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 7.1066e-04 - val_accuracy: 0.7312 - val_loss: 1.4977\n",
            "Epoch 70/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 7.5278e-04 - val_accuracy: 0.7312 - val_loss: 1.4937\n",
            "Epoch 71/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9993 - loss: 0.0043 - val_accuracy: 0.7437 - val_loss: 1.5189\n",
            "Epoch 72/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9983 - loss: 0.0046 - val_accuracy: 0.7437 - val_loss: 1.5149\n",
            "Epoch 73/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0097 - val_accuracy: 0.7500 - val_loss: 1.5110\n",
            "Epoch 74/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 0.7500 - val_loss: 1.4865\n",
            "Epoch 75/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.7500 - val_loss: 1.4712\n",
            "Epoch 76/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.7500 - val_loss: 1.4701\n",
            "Epoch 77/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9980 - loss: 0.0110 - val_accuracy: 0.7437 - val_loss: 1.4915\n",
            "Epoch 78/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.7437 - val_loss: 1.4936\n",
            "Epoch 79/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.7437 - val_loss: 1.5046\n",
            "Epoch 80/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 9.0860e-04 - val_accuracy: 0.7500 - val_loss: 1.5222\n",
            "Epoch 81/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9939 - loss: 0.0095 - val_accuracy: 0.7437 - val_loss: 1.4986\n",
            "Epoch 82/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9958 - loss: 0.0091 - val_accuracy: 0.7437 - val_loss: 1.4558\n",
            "Epoch 83/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7312 - val_loss: 1.4375\n",
            "Epoch 84/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.7437 - val_loss: 1.4464\n",
            "Epoch 85/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9982 - loss: 0.0042 - val_accuracy: 0.7500 - val_loss: 1.4540\n",
            "Epoch 86/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9988 - loss: 0.0052 - val_accuracy: 0.7500 - val_loss: 1.4630\n",
            "Epoch 87/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.7563 - val_loss: 1.4693\n",
            "Epoch 88/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9976 - loss: 0.0140 - val_accuracy: 0.7563 - val_loss: 1.5053\n",
            "Epoch 89/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.7563 - val_loss: 1.5466\n",
            "Epoch 90/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9983 - loss: 0.0058 - val_accuracy: 0.7500 - val_loss: 1.5779\n",
            "Epoch 91/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0042 - val_accuracy: 0.7500 - val_loss: 1.6144\n",
            "Epoch 92/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9945 - loss: 0.0129 - val_accuracy: 0.7500 - val_loss: 1.5775\n",
            "Epoch 93/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9939 - loss: 0.0074 - val_accuracy: 0.7563 - val_loss: 1.5016\n",
            "Epoch 94/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9946 - loss: 0.0152 - val_accuracy: 0.7250 - val_loss: 1.5909\n",
            "Epoch 95/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0029 - val_accuracy: 0.7188 - val_loss: 1.6118\n",
            "Epoch 96/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9907 - loss: 0.0141 - val_accuracy: 0.7500 - val_loss: 1.6582\n",
            "Epoch 97/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9911 - loss: 0.0206 - val_accuracy: 0.7437 - val_loss: 1.6516\n",
            "Epoch 98/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.0078 - val_accuracy: 0.7437 - val_loss: 1.6941\n",
            "Epoch 99/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0059 - val_accuracy: 0.7500 - val_loss: 1.7423\n",
            "Epoch 100/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0060 - val_accuracy: 0.7563 - val_loss: 1.7417\n",
            "TF-IDF Model Test Accuracy: 0.7563\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "TF-IDF Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          AI       0.75      0.76      0.76        80\n",
            "       HUMAN       0.76      0.75      0.75        80\n",
            "\n",
            "    accuracy                           0.76       160\n",
            "   macro avg       0.76      0.76      0.76       160\n",
            "weighted avg       0.76      0.76      0.76       160\n",
            "\n",
            "Training with Count Vectorizer features...\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.4840 - loss: 1.3845 - val_accuracy: 0.5000 - val_loss: 0.6868\n",
            "Epoch 2/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6774 - loss: 0.6765 - val_accuracy: 0.5000 - val_loss: 0.6996\n",
            "Epoch 3/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7882 - loss: 0.4988 - val_accuracy: 0.5000 - val_loss: 0.7131\n",
            "Epoch 4/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8071 - loss: 0.4594 - val_accuracy: 0.5000 - val_loss: 0.7446\n",
            "Epoch 5/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8392 - loss: 0.3740 - val_accuracy: 0.5000 - val_loss: 0.7645\n",
            "Epoch 6/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8678 - loss: 0.2737 - val_accuracy: 0.5063 - val_loss: 0.7688\n",
            "Epoch 7/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8952 - loss: 0.2406 - val_accuracy: 0.5063 - val_loss: 0.7801\n",
            "Epoch 8/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9289 - loss: 0.1831 - val_accuracy: 0.5250 - val_loss: 0.7684\n",
            "Epoch 9/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9622 - loss: 0.1066 - val_accuracy: 0.5500 - val_loss: 0.7625\n",
            "Epoch 10/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9463 - loss: 0.1389 - val_accuracy: 0.5688 - val_loss: 0.7440\n",
            "Epoch 11/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9707 - loss: 0.0997 - val_accuracy: 0.5875 - val_loss: 0.7298\n",
            "Epoch 12/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9629 - loss: 0.0872 - val_accuracy: 0.6313 - val_loss: 0.6875\n",
            "Epoch 13/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9636 - loss: 0.1084 - val_accuracy: 0.6687 - val_loss: 0.6605\n",
            "Epoch 14/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9840 - loss: 0.0536 - val_accuracy: 0.6562 - val_loss: 0.6319\n",
            "Epoch 15/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9853 - loss: 0.0542 - val_accuracy: 0.7063 - val_loss: 0.6227\n",
            "Epoch 16/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9737 - loss: 0.0701 - val_accuracy: 0.7188 - val_loss: 0.6033\n",
            "Epoch 17/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9731 - loss: 0.0674 - val_accuracy: 0.7375 - val_loss: 0.5797\n",
            "Epoch 18/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9857 - loss: 0.0445 - val_accuracy: 0.7625 - val_loss: 0.5609\n",
            "Epoch 19/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9807 - loss: 0.0445 - val_accuracy: 0.7625 - val_loss: 0.5536\n",
            "Epoch 20/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9859 - loss: 0.0435 - val_accuracy: 0.7688 - val_loss: 0.5535\n",
            "Epoch 21/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9884 - loss: 0.0263 - val_accuracy: 0.7812 - val_loss: 0.5537\n",
            "Epoch 22/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9878 - loss: 0.0280 - val_accuracy: 0.7812 - val_loss: 0.5699\n",
            "Epoch 23/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9793 - loss: 0.0482 - val_accuracy: 0.7812 - val_loss: 0.5860\n",
            "Epoch 24/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9910 - loss: 0.0229 - val_accuracy: 0.7563 - val_loss: 0.6186\n",
            "Epoch 25/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0237 - val_accuracy: 0.7688 - val_loss: 0.6653\n",
            "Epoch 26/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9969 - loss: 0.0167 - val_accuracy: 0.7688 - val_loss: 0.6842\n",
            "Epoch 27/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9928 - loss: 0.0284 - val_accuracy: 0.7688 - val_loss: 0.7150\n",
            "Epoch 28/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9921 - loss: 0.0295 - val_accuracy: 0.7625 - val_loss: 0.7305\n",
            "Epoch 29/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9953 - loss: 0.0157 - val_accuracy: 0.7563 - val_loss: 0.7438\n",
            "Epoch 30/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9942 - loss: 0.0224 - val_accuracy: 0.7625 - val_loss: 0.7612\n",
            "Epoch 31/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9886 - loss: 0.0346 - val_accuracy: 0.7750 - val_loss: 0.7652\n",
            "Epoch 32/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0110 - val_accuracy: 0.7875 - val_loss: 0.7750\n",
            "Epoch 33/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9985 - loss: 0.0115 - val_accuracy: 0.8000 - val_loss: 0.7878\n",
            "Epoch 34/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9869 - loss: 0.0591 - val_accuracy: 0.7812 - val_loss: 0.7752\n",
            "Epoch 35/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9831 - loss: 0.0424 - val_accuracy: 0.7750 - val_loss: 0.8040\n",
            "Epoch 36/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9905 - loss: 0.0213 - val_accuracy: 0.7625 - val_loss: 0.8188\n",
            "Epoch 37/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9929 - loss: 0.0166 - val_accuracy: 0.7563 - val_loss: 0.8156\n",
            "Epoch 38/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9904 - loss: 0.0313 - val_accuracy: 0.7750 - val_loss: 0.8051\n",
            "Epoch 39/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9918 - loss: 0.0209 - val_accuracy: 0.7625 - val_loss: 0.8034\n",
            "Epoch 40/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9919 - loss: 0.0154 - val_accuracy: 0.7750 - val_loss: 0.8146\n",
            "Epoch 41/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0157 - val_accuracy: 0.7812 - val_loss: 0.8274\n",
            "Epoch 42/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9989 - loss: 0.0083 - val_accuracy: 0.7750 - val_loss: 0.8375\n",
            "Epoch 43/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9950 - loss: 0.0155 - val_accuracy: 0.7500 - val_loss: 0.8498\n",
            "Epoch 44/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9979 - loss: 0.0076 - val_accuracy: 0.7688 - val_loss: 0.8581\n",
            "Epoch 45/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9936 - loss: 0.0225 - val_accuracy: 0.7688 - val_loss: 0.8915\n",
            "Epoch 46/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9940 - loss: 0.0150 - val_accuracy: 0.7563 - val_loss: 0.9188\n",
            "Epoch 47/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9936 - loss: 0.0312 - val_accuracy: 0.7563 - val_loss: 0.9191\n",
            "Epoch 48/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 0.7625 - val_loss: 0.9270\n",
            "Epoch 49/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9842 - loss: 0.0459 - val_accuracy: 0.7688 - val_loss: 0.9335\n",
            "Epoch 50/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9943 - loss: 0.0136 - val_accuracy: 0.7688 - val_loss: 0.9364\n",
            "Epoch 51/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.7750 - val_loss: 0.9467\n",
            "Epoch 52/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 0.0064 - val_accuracy: 0.7750 - val_loss: 0.9511\n",
            "Epoch 53/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0053 - val_accuracy: 0.7875 - val_loss: 0.9702\n",
            "Epoch 54/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0060 - val_accuracy: 0.7937 - val_loss: 0.9880\n",
            "Epoch 55/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 0.0060 - val_accuracy: 0.7812 - val_loss: 1.0093\n",
            "Epoch 56/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9989 - loss: 0.0048 - val_accuracy: 0.7875 - val_loss: 1.0177\n",
            "Epoch 57/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0074 - val_accuracy: 0.7688 - val_loss: 1.0256\n",
            "Epoch 58/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.7812 - val_loss: 1.0520\n",
            "Epoch 59/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9956 - loss: 0.0136 - val_accuracy: 0.7625 - val_loss: 1.0813\n",
            "Epoch 60/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9952 - loss: 0.0163 - val_accuracy: 0.7625 - val_loss: 1.0766\n",
            "Epoch 61/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9946 - loss: 0.0099 - val_accuracy: 0.7688 - val_loss: 1.0654\n",
            "Epoch 62/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9974 - loss: 0.0040 - val_accuracy: 0.7750 - val_loss: 1.0723\n",
            "Epoch 63/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7750 - val_loss: 1.0959\n",
            "Epoch 64/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 0.7812 - val_loss: 1.0987\n",
            "Epoch 65/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9988 - loss: 0.0038 - val_accuracy: 0.7812 - val_loss: 1.0910\n",
            "Epoch 66/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9977 - loss: 0.0121 - val_accuracy: 0.7750 - val_loss: 1.0737\n",
            "Epoch 67/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9997 - loss: 0.0059 - val_accuracy: 0.7812 - val_loss: 1.0752\n",
            "Epoch 68/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0061 - val_accuracy: 0.7812 - val_loss: 1.0921\n",
            "Epoch 69/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9959 - loss: 0.0103 - val_accuracy: 0.7750 - val_loss: 1.1026\n",
            "Epoch 70/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9964 - loss: 0.0069 - val_accuracy: 0.7750 - val_loss: 1.1296\n",
            "Epoch 71/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.7750 - val_loss: 1.1470\n",
            "Epoch 72/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9986 - loss: 0.0025 - val_accuracy: 0.7750 - val_loss: 1.1522\n",
            "Epoch 73/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9993 - loss: 0.0044 - val_accuracy: 0.7812 - val_loss: 1.1398\n",
            "Epoch 74/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9980 - loss: 0.0072 - val_accuracy: 0.7875 - val_loss: 1.1608\n",
            "Epoch 75/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0037 - val_accuracy: 0.7875 - val_loss: 1.1683\n",
            "Epoch 76/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9921 - loss: 0.0236 - val_accuracy: 0.7750 - val_loss: 1.1523\n",
            "Epoch 77/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.7875 - val_loss: 1.1571\n",
            "Epoch 78/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9964 - loss: 0.0101 - val_accuracy: 0.7750 - val_loss: 1.1696\n",
            "Epoch 79/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.7812 - val_loss: 1.1922\n",
            "Epoch 80/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0076 - val_accuracy: 0.7875 - val_loss: 1.1900\n",
            "Epoch 81/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7750 - val_loss: 1.2039\n",
            "Epoch 82/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9950 - loss: 0.0131 - val_accuracy: 0.7625 - val_loss: 1.2105\n",
            "Epoch 83/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9821 - loss: 0.0524 - val_accuracy: 0.7812 - val_loss: 1.2474\n",
            "Epoch 84/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9934 - loss: 0.0219 - val_accuracy: 0.7812 - val_loss: 1.3154\n",
            "Epoch 85/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9946 - loss: 0.0060 - val_accuracy: 0.7812 - val_loss: 1.3264\n",
            "Epoch 86/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9932 - loss: 0.0107 - val_accuracy: 0.7812 - val_loss: 1.3288\n",
            "Epoch 87/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9993 - loss: 0.0041 - val_accuracy: 0.7812 - val_loss: 1.3275\n",
            "Epoch 88/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9953 - loss: 0.0104 - val_accuracy: 0.7750 - val_loss: 1.3615\n",
            "Epoch 89/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0068 - val_accuracy: 0.7750 - val_loss: 1.3634\n",
            "Epoch 90/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9949 - loss: 0.0133 - val_accuracy: 0.7750 - val_loss: 1.3645\n",
            "Epoch 91/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.7688 - val_loss: 1.3822\n",
            "Epoch 92/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0031 - val_accuracy: 0.7688 - val_loss: 1.3899\n",
            "Epoch 93/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9978 - loss: 0.0061 - val_accuracy: 0.7688 - val_loss: 1.3889\n",
            "Epoch 94/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0026 - val_accuracy: 0.7750 - val_loss: 1.3944\n",
            "Epoch 95/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7625 - val_loss: 1.3779\n",
            "Epoch 96/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 0.7625 - val_loss: 1.3967\n",
            "Epoch 97/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9991 - loss: 0.0018 - val_accuracy: 0.7625 - val_loss: 1.3957\n",
            "Epoch 98/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.7625 - val_loss: 1.4026\n",
            "Epoch 99/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9921 - loss: 0.0218 - val_accuracy: 0.7750 - val_loss: 1.3985\n",
            "Epoch 100/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9982 - loss: 0.0060 - val_accuracy: 0.7625 - val_loss: 1.4421\n",
            "Count Vectorizer Model Test Accuracy: 0.7625\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Count Vectorizer Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          AI       0.74      0.81      0.77        80\n",
            "       HUMAN       0.79      0.71      0.75        80\n",
            "\n",
            "    accuracy                           0.76       160\n",
            "   macro avg       0.77      0.76      0.76       160\n",
            "weighted avg       0.77      0.76      0.76       160\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "import pickle\n",
        "\n",
        "file_path = \"/content/mal_training_data_hum_ai.csv\"\n",
        "dataset_df = pd.read_csv(file_path)\n",
        "dataset_df.columns = ['id', 'transcript', 'class_label']\n",
        "print(dataset_df.head())\n",
        "\n",
        "stop = [\n",
        "    \"അവൻ\", \"അവൾ\", \"അവർ\", \"ആ\", \"ആകാം\", \"ആകുന്നു\", \"ആകും\", \"ആകെയുള്ള\", \"ആകെയുള്ളത്\", \"ആകെയുള്ളവ\", \"ആകെയുള്ളവർ\",\n",
        "    \"ആകെയുള്ളവൻ\", \"ആകെയുള്ളവൾ\", \"ആകെയുള്ളവൾക്ക്\", \"ആകുള്ളവൾക്ക്‌\", \"ഇത്\", \"ഇതിൽ\", \"ഇതിന്റെ\", \"ഇതും\", \"ഇതെല്ലാം\",\n",
        "    \"ഇവ\", \"ഇവയിൽ\", \"ഇവയുടെ\", \"ഇവയും\", \"ഇവയെല്ലാം\", \"ഇവൻ\", \"ഇവൾ\", \"ഇവർ\", \"ഇവരുടെ\", \"ഇവരിൽ\", \"ഇവരെയും\", \"ഇവരെയെല്ലാം\",\n",
        "    \"ഇവരോട്\", \"ഇവരോടും\", \"ഇവരോടുള്ള\", \"ഇവരോടുള്ളത്\", \"ഇവരോടുള്ളവ\", \"ഇവരോടുള്ളവർ\", \"ഇവരോടുള്ളവൻ\", \"ഇവരോടുള്ളവൾ\",\n",
        "    \"ഇവരോടുള്ളവൾക്ക്\", \"ഇവരോടുള്ളവൾക്ക്‌\"\n",
        "]\n",
        "\n",
        "def preprocess_malayalam_text(text):\n",
        "    \"\"\"Preprocess Malayalam text by normalizing, tokenizing, and removing stopwords.\"\"\"\n",
        "    normalizer_factory = IndicNormalizerFactory()\n",
        "    normalizer = normalizer_factory.get_normalizer(\"ml\")\n",
        "    text = normalizer.normalize(text)\n",
        "    tokens = list(indic_tokenize.trivial_tokenize(text, lang=\"ml\"))\n",
        "    tokens = [token for token in tokens if token not in stop]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "dataset_df['cleaned_transcript'] = dataset_df['transcript'].apply(preprocess_malayalam_text)\n",
        "print(dataset_df.head())\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "dataset_df['encoded_label'] = label_encoder.fit_transform(dataset_df['class_label'])\n",
        "\n",
        "label_encoder_path = \"malayalam_label_encoder.pkl\"\n",
        "with open(label_encoder_path, \"wb\") as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "print(f\"Label encoder saved to {label_encoder_path}\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    dataset_df['cleaned_transcript'], dataset_df['encoded_label'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train).toarray()\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test).toarray()\n",
        "\n",
        "count_vectorizer = CountVectorizer(max_features=5000)\n",
        "X_train_count = count_vectorizer.fit_transform(X_train).toarray()\n",
        "X_test_count = count_vectorizer.transform(X_test).toarray()\n",
        "\n",
        "with open(\"tfidf_vectorizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tfidf_vectorizer, f)\n",
        "\n",
        "with open(\"count_vectorizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(count_vectorizer, f)\n",
        "\n",
        "print(\"TF-IDF and Count Vectorizers saved successfully.\")\n",
        "\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "\n",
        "def build_model(input_dim, output_dim):\n",
        "    model = Sequential([\n",
        "        Dense(256, input_dim=input_dim, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(output_dim, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "print(\"Training with TF-IDF features...\")\n",
        "model_tfidf = build_model(X_train_tfidf.shape[1], len(label_encoder.classes_))\n",
        "history_tfidf = model_tfidf.fit(\n",
        "    X_train_tfidf, y_train_cat,\n",
        "    validation_data=(X_test_tfidf, y_test_cat),\n",
        "    epochs=100, batch_size=32, verbose=1\n",
        ")\n",
        "\n",
        "loss_tfidf, accuracy_tfidf = model_tfidf.evaluate(X_test_tfidf, y_test_cat, verbose=0)\n",
        "print(f\"TF-IDF Model Test Accuracy: {accuracy_tfidf:.4f}\")\n",
        "\n",
        "y_pred_tfidf = model_tfidf.predict(X_test_tfidf)\n",
        "y_pred_tfidf_labels = np.argmax(y_pred_tfidf, axis=1)\n",
        "print(\"TF-IDF Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_tfidf_labels, target_names=label_encoder.classes_))\n",
        "\n",
        "\n",
        "print(\"Training with Count Vectorizer features...\")\n",
        "model_count = build_model(X_train_count.shape[1], len(label_encoder.classes_))\n",
        "history_count = model_count.fit(\n",
        "    X_train_count, y_train_cat,\n",
        "    validation_data=(X_test_count, y_test_cat),\n",
        "    epochs=100, batch_size=32, verbose=1\n",
        ")\n",
        "\n",
        "loss_count, accuracy_count = model_count.evaluate(X_test_count, y_test_cat, verbose=0)\n",
        "print(f\"Count Vectorizer Model Test Accuracy: {accuracy_count:.4f}\")\n",
        "\n",
        "y_pred_count = model_count.predict(X_test_count)\n",
        "y_pred_count_labels = np.argmax(y_pred_count, axis=1)\n",
        "print(\"Count Vectorizer Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_count_labels, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84jGV6uSKgRQ"
      },
      "source": [
        "MALAYALAM xlm-roberta-large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cf73d17d7c4a4bdd9a757f39a9dd2021",
            "0a8a93826734490b8a8393bc16510bce",
            "c8c4ca9a78204677a16808acb8510e80",
            "b0409e6fa86f4514b9b610438e4ef36d",
            "d0e83ea91a784e56977896cd6d5eebd2",
            "b2331ae681d2420e973c6daa38bc2491",
            "cf47ff2517044e04b5b6ce380bb9459d",
            "35024dccd6bc43ee9bd336654ccab10c",
            "a330ab2d45c547f6afef386bef71aa7f",
            "4fd88c3170d44b8e88735be041903f2c",
            "a5585b75eb31446cb9ce698cacd86183",
            "f08c792b038445a09da64f7403693a73",
            "7631b3c700664994b476a3db28ad1927",
            "8cddc084eab64e7d8bbd8561aa235ee8",
            "695b4f0d29d743e399505fe9a325d736",
            "6101199d94e9480cadfc0d974b1a555f",
            "a5f4f732d2f243c6b3495cd5bdc36d43",
            "3eee6a60fa634d699e11e7b58418a7dd",
            "d04754271eae4e1680547b73363095c9",
            "4246c2b8d1994ebfa538da0451818b5c",
            "9d53cd512d2c49d5946b8008518d74e6",
            "b95501bae8cc49d5b7f2a75241c635f0",
            "b250f3f51212410f89d8bf023b461268",
            "df1bcd3e52094587a9c46ade04df65da",
            "f58a381662e54ab39f50056efd31f9ba",
            "f13911ea7ccf4ef1b24917e1a0bae1c4",
            "74dfb116fb10461e9365f3eeba58c1c6",
            "f93a656c6fce480480e65df7910f28e1",
            "d672faf7d90f4ac3908de5339aae75c0",
            "3d8bc55b93534deab6081b5c6f376d2b",
            "1ed20a84879846cda13f547bb2bd2e10",
            "4609e512116045c9a6326c2c8ad277d2",
            "3afd9818a1cc457da76571e36c8cf8d4",
            "d06cd82eb1b74bab8fb12e0e85117d78",
            "61c4ee9e7cec4832b32010dba2cb0a66",
            "417f879758cc4b6db7200b0e3dfdf3d3",
            "073bc76663be415897f87a57bc290cb9",
            "6dda9e7810514db88cf95683b1d13e3e",
            "98eefd2bb9344c41a915a5b5b4245e98",
            "adcadc537d75422bad3fa4657d65973e",
            "9bbe21d028df41f68883c65fc2377f85",
            "17c343faf3b241ca91175991bc4042be",
            "4fff8f44d8ea461693c2291ca4f1a1b4",
            "712e6167d98348bb81e37899d0f28a29",
            "9ee8c0e3114f4f8cbe3bb51d968d4f0e",
            "e8364238314c446b8841209ac27d8b30",
            "f5c661a8805a4ccd8f4acb5a914c02c0",
            "ec330c0bb88c410f8eec9ddc24c2291e",
            "f3b5c16a03514d2d9a8a938ab03d0a9d",
            "b1bd168ee8324c04894216dea21fe1d9",
            "00c6ff15e25d402cb2e816b1c896b899",
            "a74b430a2c944e71964c36acd30d722f",
            "090d344035fa43a6815a88e6a2763548",
            "3a3533706dcb46409bf0655c6042846d",
            "e0de30e4aea44cc4a6a56b13d41d1990"
          ]
        },
        "id": "cWxhR9o_G5U0",
        "outputId": "6eb7879c-ce19-48af-bfa1-305804129b0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                id                                         transcript  \\\n",
            "0  MAL_HUAI_TR_001  ഞാൻ കുറച്ച് കാലമായി മുച്ചട്ച്ചിൻ്റെ ഫേസ് വാഷ് ...   \n",
            "1  MAL_HUAI_TR_002           ഈ ഫേസ് വാഷ് തണുപ്പ് വെതറിലും ഉപയോഗിക്കാം   \n",
            "2  MAL_HUAI_TR_003  അണ്ണാ എനിക്ക് 14 വയസ് ആയ തേയോളു എനിക്ക് സ്കിൻക...   \n",
            "3  MAL_HUAI_TR_004  ബ്രോ ഇതെല്ലം യൂസ്  ആക്കീട്ട് നൈറ്റ് പിന്നെ വേറ...   \n",
            "4  MAL_HUAI_TR_005    ഇത് ഫേസ് വാഷ് ഡെയിലി ചെയ്താ സ്കിൻകെയറിന് നല്ലതാ   \n",
            "\n",
            "  class_label  \n",
            "0       HUMAN  \n",
            "1       HUMAN  \n",
            "2       HUMAN  \n",
            "3       HUMAN  \n",
            "4       HUMAN  \n",
            "                id                                         transcript  \\\n",
            "0  MAL_HUAI_TR_001  ഞാൻ കുറച്ച് കാലമായി മുച്ചട്ച്ചിൻ്റെ ഫേസ് വാഷ് ...   \n",
            "1  MAL_HUAI_TR_002           ഈ ഫേസ് വാഷ് തണുപ്പ് വെതറിലും ഉപയോഗിക്കാം   \n",
            "2  MAL_HUAI_TR_003  അണ്ണാ എനിക്ക് 14 വയസ് ആയ തേയോളു എനിക്ക് സ്കിൻക...   \n",
            "3  MAL_HUAI_TR_004  ബ്രോ ഇതെല്ലം യൂസ്  ആക്കീട്ട് നൈറ്റ് പിന്നെ വേറ...   \n",
            "4  MAL_HUAI_TR_005    ഇത് ഫേസ് വാഷ് ഡെയിലി ചെയ്താ സ്കിൻകെയറിന് നല്ലതാ   \n",
            "\n",
            "  class_label                                 cleaned_transcript  \n",
            "0       HUMAN  ഞാൻ കുറച്ച് കാലമായി മുച്ചട്ച്ചിൻ്റെ ഫേസ് വാഷ് ...  \n",
            "1       HUMAN           ഈ ഫേസ് വാഷ് തണുപ്പ് വെതറിലും ഉപയോഗിക്കാം  \n",
            "2       HUMAN  അണ്ണാ എനിക്ക് 14 വയസ് ആയ തേയോളു എനിക്ക് സ്കിൻക...  \n",
            "3       HUMAN  ബ്രോ ഇതെല്ലം യൂസ് ആക്കീട്ട് നൈറ്റ് പിന്നെ വേറെ...  \n",
            "4       HUMAN        ഫേസ് വാഷ് ഡെയിലി ചെയ്താ സ്കിൻകെയറിന് നല്ലതാ  \n",
            "Label encoder saved to malayalam_label_encoder.pkl\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf73d17d7c4a4bdd9a757f39a9dd2021",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f08c792b038445a09da64f7403693a73",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b250f3f51212410f89d8bf023b461268",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d06cd82eb1b74bab8fb12e0e85117d78",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ee8c0e3114f4f8cbe3bb51d968d4f0e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with XLM-Roberta embeddings...\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.6557 - loss: 0.9565 - val_accuracy: 0.5000 - val_loss: 0.6536\n",
            "Epoch 2/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8854 - loss: 0.2965 - val_accuracy: 0.5000 - val_loss: 0.6191\n",
            "Epoch 3/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9046 - loss: 0.2532 - val_accuracy: 0.6812 - val_loss: 0.5374\n",
            "Epoch 4/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9473 - loss: 0.1282 - val_accuracy: 0.7500 - val_loss: 0.4958\n",
            "Epoch 5/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8983 - loss: 0.2835 - val_accuracy: 0.5000 - val_loss: 0.5900\n",
            "Epoch 6/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9353 - loss: 0.1688 - val_accuracy: 0.8188 - val_loss: 0.4536\n",
            "Epoch 7/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9353 - loss: 0.1497 - val_accuracy: 0.8875 - val_loss: 0.3670\n",
            "Epoch 8/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9640 - loss: 0.0950 - val_accuracy: 0.9375 - val_loss: 0.3646\n",
            "Epoch 9/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9663 - loss: 0.0959 - val_accuracy: 0.9438 - val_loss: 0.3153\n",
            "Epoch 10/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9759 - loss: 0.0673 - val_accuracy: 0.9062 - val_loss: 0.3117\n",
            "Epoch 11/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9740 - loss: 0.0740 - val_accuracy: 0.6938 - val_loss: 0.4491\n",
            "Epoch 12/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9887 - loss: 0.0652 - val_accuracy: 0.9438 - val_loss: 0.2272\n",
            "Epoch 13/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9848 - loss: 0.0389 - val_accuracy: 0.6938 - val_loss: 0.4535\n",
            "Epoch 14/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9761 - loss: 0.0602 - val_accuracy: 0.9125 - val_loss: 0.2803\n",
            "Epoch 15/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9799 - loss: 0.0500 - val_accuracy: 0.9375 - val_loss: 0.1745\n",
            "Epoch 16/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9789 - loss: 0.0542 - val_accuracy: 0.6000 - val_loss: 0.7477\n",
            "Epoch 17/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9884 - loss: 0.0429 - val_accuracy: 0.9312 - val_loss: 0.1777\n",
            "Epoch 18/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9756 - loss: 0.0724 - val_accuracy: 0.9375 - val_loss: 0.1702\n",
            "Epoch 19/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9834 - loss: 0.0557 - val_accuracy: 0.9563 - val_loss: 0.1350\n",
            "Epoch 20/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9965 - loss: 0.0244 - val_accuracy: 0.8500 - val_loss: 0.3345\n",
            "Epoch 21/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9792 - loss: 0.0456 - val_accuracy: 0.9312 - val_loss: 0.1715\n",
            "Epoch 22/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9900 - loss: 0.0330 - val_accuracy: 0.6000 - val_loss: 1.0412\n",
            "Epoch 23/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9804 - loss: 0.0366 - val_accuracy: 0.9375 - val_loss: 0.1711\n",
            "Epoch 24/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9888 - loss: 0.0382 - val_accuracy: 0.8625 - val_loss: 0.3856\n",
            "Epoch 25/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9932 - loss: 0.0203 - val_accuracy: 0.8813 - val_loss: 0.3725\n",
            "Epoch 26/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9884 - loss: 0.0549 - val_accuracy: 0.9312 - val_loss: 0.1616\n",
            "Epoch 27/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9941 - loss: 0.0171 - val_accuracy: 0.8313 - val_loss: 0.5161\n",
            "Epoch 28/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9909 - loss: 0.0223 - val_accuracy: 0.5938 - val_loss: 1.3177\n",
            "Epoch 29/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9789 - loss: 0.0514 - val_accuracy: 0.9125 - val_loss: 0.1917\n",
            "Epoch 30/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9718 - loss: 0.0564 - val_accuracy: 0.7125 - val_loss: 2.1612\n",
            "Epoch 31/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9882 - loss: 0.0395 - val_accuracy: 0.8250 - val_loss: 0.4873\n",
            "Epoch 32/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9814 - loss: 0.0561 - val_accuracy: 0.8250 - val_loss: 1.0653\n",
            "Epoch 33/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9882 - loss: 0.0415 - val_accuracy: 0.9438 - val_loss: 0.1562\n",
            "Epoch 34/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9891 - loss: 0.0242 - val_accuracy: 0.8062 - val_loss: 1.3363\n",
            "Epoch 35/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9940 - loss: 0.0167 - val_accuracy: 0.9375 - val_loss: 0.3052\n",
            "Epoch 36/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9814 - loss: 0.0556 - val_accuracy: 0.9312 - val_loss: 0.1900\n",
            "Epoch 37/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9934 - loss: 0.0164 - val_accuracy: 0.5312 - val_loss: 3.4558\n",
            "Epoch 38/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9921 - loss: 0.0254 - val_accuracy: 0.7063 - val_loss: 1.0086\n",
            "Epoch 39/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9820 - loss: 0.0472 - val_accuracy: 0.9312 - val_loss: 0.1496\n",
            "Epoch 40/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9879 - loss: 0.0288 - val_accuracy: 0.9250 - val_loss: 0.2103\n",
            "Epoch 41/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9811 - loss: 0.0596 - val_accuracy: 0.8375 - val_loss: 0.4991\n",
            "Epoch 42/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9864 - loss: 0.0383 - val_accuracy: 0.7563 - val_loss: 1.5945\n",
            "Epoch 43/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9885 - loss: 0.0373 - val_accuracy: 0.8188 - val_loss: 1.0926\n",
            "Epoch 44/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9928 - loss: 0.0271 - val_accuracy: 0.9438 - val_loss: 0.2136\n",
            "Epoch 45/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9752 - loss: 0.0607 - val_accuracy: 0.5688 - val_loss: 2.5773\n",
            "Epoch 46/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9925 - loss: 0.0146 - val_accuracy: 0.5938 - val_loss: 1.9088\n",
            "Epoch 47/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9870 - loss: 0.0293 - val_accuracy: 0.9250 - val_loss: 0.2483\n",
            "Epoch 48/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9945 - loss: 0.0192 - val_accuracy: 0.9563 - val_loss: 0.1532\n",
            "Epoch 49/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9796 - loss: 0.0540 - val_accuracy: 0.9250 - val_loss: 0.2470\n",
            "Epoch 50/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9924 - loss: 0.0228 - val_accuracy: 0.9438 - val_loss: 0.1982\n",
            "Test Accuracy: 0.9438\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          AI       1.00      0.89      0.94        80\n",
            "       HUMAN       0.90      1.00      0.95        80\n",
            "\n",
            "    accuracy                           0.94       160\n",
            "   macro avg       0.95      0.94      0.94       160\n",
            "weighted avg       0.95      0.94      0.94       160\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report\n",
        "import pickle\n",
        "\n",
        "file_path = \"/content/mal_training_data_hum_ai.csv\"\n",
        "dataset_df = pd.read_csv(file_path)\n",
        "dataset_df.columns = ['id', 'transcript', 'class_label']\n",
        "print(dataset_df.head())\n",
        "\n",
        "stop = [\n",
        "    \"അവൻ\", \"അവൾ\", \"അവർ\", \"ആ\", \"ആകാം\", \"ആകുന്നു\", \"ആകും\", \"ആകെയുള്ള\", \"ആകെയുള്ളത്\", \"ആകെയുള്ളവ\", \"ആകെയുള്ളവർ\",\n",
        "    \"ആകെയുള്ളവൻ\", \"ആകെയുള്ളവൾ\", \"ആകെയുള്ളവൾക്ക്\", \"ആകുള്ളവൾക്ക്‌\", \"ഇത്\", \"ഇതിൽ\", \"ഇതിന്റെ\", \"ഇതും\", \"ഇതെല്ലാം\",\n",
        "    \"ഇവ\", \"ഇവയിൽ\", \"ഇവയുടെ\", \"ഇവയും\", \"ഇവയെല്ലാം\", \"ഇവൻ\", \"ഇവൾ\", \"ഇവർ\", \"ഇവരുടെ\", \"ഇവരിൽ\", \"ഇവരെയും\", \"ഇവരെയെല്ലാം\",\n",
        "    \"ഇവരോട്\", \"ഇവരോടും\", \"ഇവരോടുള്ള\", \"ഇവരോടുള്ളത്\", \"ഇവരോടുള്ളവ\", \"ഇവരോടുള്ളവർ\", \"ഇവരോടുള്ളവൻ\", \"ഇവരോടുള്ളവൾ\",\n",
        "    \"ഇവരോടുള്ളവൾക്ക്\", \"ഇവരോടുള്ളവൾക്ക്‌\"\n",
        "]\n",
        "\n",
        "def preprocess_malayalam_text(text):\n",
        "    \"\"\"Preprocess Malayalam text by normalizing, tokenizing, and removing stopwords.\"\"\"\n",
        "    normalizer_factory = IndicNormalizerFactory()\n",
        "    normalizer = normalizer_factory.get_normalizer(\"ml\")\n",
        "    text = normalizer.normalize(text)\n",
        "    tokens = list(indic_tokenize.trivial_tokenize(text, lang=\"ml\"))\n",
        "    tokens = [token for token in tokens if token not in stop]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "dataset_df['cleaned_transcript'] = dataset_df['transcript'].apply(preprocess_malayalam_text)\n",
        "print(dataset_df.head())\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "dataset_df['encoded_label'] = label_encoder.fit_transform(dataset_df['class_label'])\n",
        "\n",
        "label_encoder_path = \"malayalam_label_encoder.pkl\"\n",
        "with open(label_encoder_path, \"wb\") as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "print(f\"Label encoder saved to {label_encoder_path}\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    dataset_df['cleaned_transcript'], dataset_df['encoded_label'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "model_name = \"xlm-roberta-large\"  \n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_texts(texts, tokenizer, max_length=512):\n",
        "    inputs = tokenizer(\n",
        "        texts.tolist(),\n",
        "        max_length=max_length,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    return inputs\n",
        "\n",
        "X_train_tokens = tokenize_texts(X_train, tokenizer)\n",
        "X_test_tokens = tokenize_texts(X_test, tokenizer)\n",
        "\n",
        "def extract_embeddings(tokens, model):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**tokens)\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1).numpy()  \n",
        "    return embeddings\n",
        "\n",
        "X_train_embeddings = extract_embeddings(X_train_tokens, model)\n",
        "X_test_embeddings = extract_embeddings(X_test_tokens, model)\n",
        "\n",
        "def build_model(input_dim, output_dim):\n",
        "    model = Sequential([\n",
        "        Dense(256, input_dim=input_dim, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(output_dim, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "\n",
        "print(\"Training with XLM-Roberta embeddings...\")\n",
        "classification_model = build_model(X_train_embeddings.shape[1], len(label_encoder.classes_))\n",
        "history = classification_model.fit(\n",
        "    X_train_embeddings, y_train_cat,\n",
        "    validation_data=(X_test_embeddings, y_test_cat),\n",
        "    epochs=50, batch_size=32, verbose=1\n",
        ")\n",
        "\n",
        "loss, accuracy = classification_model.evaluate(X_test_embeddings, y_test_cat, verbose=0)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "y_pred = classification_model.predict(X_test_embeddings)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_labels, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4uoJN27KnqJ"
      },
      "source": [
        "TAMIL xlm-roberta-large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLcZNxURI31_",
        "outputId": "4283377e-b45c-4581-be56-7759fce52e81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                id                                         transcript  \\\n",
            "0  TAM_HUAI_TR_001  இந்த சோப்பின் மணம் மிகவும் புத்துணர்ச்சியூட்டு...   \n",
            "1  TAM_HUAI_TR_002   தோலை நன்கு சுத்தம் செய்ய இது மிகவும் சிறப்பானது.   \n",
            "2  TAM_HUAI_TR_003  இதைப் பயன்படுத்திய பிறகு, தோல் மிக மென்மையாக உ...   \n",
            "3  TAM_HUAI_TR_004  இந்த சோப்பில் இயற்கையான மூலப்பொருட்கள் பயன்படு...   \n",
            "4  TAM_HUAI_TR_005        சிறிது சோப்பு போதும், அதிக நுரை உருவாகிறது.   \n",
            "\n",
            "  class_label  \n",
            "0          AI  \n",
            "1          AI  \n",
            "2          AI  \n",
            "3          AI  \n",
            "4          AI  \n",
            "                id                                         transcript  \\\n",
            "0  TAM_HUAI_TR_001  இந்த சோப்பின் மணம் மிகவும் புத்துணர்ச்சியூட்டு...   \n",
            "1  TAM_HUAI_TR_002   தோலை நன்கு சுத்தம் செய்ய இது மிகவும் சிறப்பானது.   \n",
            "2  TAM_HUAI_TR_003  இதைப் பயன்படுத்திய பிறகு, தோல் மிக மென்மையாக உ...   \n",
            "3  TAM_HUAI_TR_004  இந்த சோப்பில் இயற்கையான மூலப்பொருட்கள் பயன்படு...   \n",
            "4  TAM_HUAI_TR_005        சிறிது சோப்பு போதும், அதிக நுரை உருவாகிறது.   \n",
            "\n",
            "  class_label                                 cleaned_transcript  \n",
            "0          AI      சோப்பின் மணம் புத்துணர்ச்சியூட்டும் வகையில் .  \n",
            "1          AI              தோலை நன்கு சுத்தம் செய்ய சிறப்பானது .  \n",
            "2          AI              இதைப் பயன்படுத்திய , தோல் மென்மையாக .  \n",
            "3          AI  சோப்பில் இயற்கையான மூலப்பொருட்கள் பயன்படுத்தப்...  \n",
            "4          AI           சிறிது சோப்பு போதும் , நுரை உருவாகிறது .  \n",
            "Label encoder saved to tamil_label_encoder.pkl\n",
            "Training with XLM-Roberta embeddings...\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7341 - loss: 0.5705 - val_accuracy: 0.4691 - val_loss: 0.6636\n",
            "Epoch 2/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8986 - loss: 0.3008 - val_accuracy: 0.4815 - val_loss: 0.6318\n",
            "Epoch 3/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9207 - loss: 0.1968 - val_accuracy: 0.5123 - val_loss: 0.5995\n",
            "Epoch 4/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9394 - loss: 0.1570 - val_accuracy: 0.6667 - val_loss: 0.5326\n",
            "Epoch 5/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9355 - loss: 0.1841 - val_accuracy: 0.9136 - val_loss: 0.4593\n",
            "Epoch 6/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9527 - loss: 0.1696 - val_accuracy: 0.9074 - val_loss: 0.4171\n",
            "Epoch 7/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9618 - loss: 0.1208 - val_accuracy: 0.8457 - val_loss: 0.4155\n",
            "Epoch 8/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9564 - loss: 0.1268 - val_accuracy: 0.8951 - val_loss: 0.3668\n",
            "Epoch 9/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9704 - loss: 0.0889 - val_accuracy: 0.9012 - val_loss: 0.3351\n",
            "Epoch 10/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9476 - loss: 0.1418 - val_accuracy: 0.9198 - val_loss: 0.2858\n",
            "Epoch 11/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9667 - loss: 0.0925 - val_accuracy: 0.8457 - val_loss: 0.3577\n",
            "Epoch 12/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9611 - loss: 0.1160 - val_accuracy: 0.9383 - val_loss: 0.2243\n",
            "Epoch 13/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9554 - loss: 0.1030 - val_accuracy: 0.9259 - val_loss: 0.2001\n",
            "Epoch 14/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9724 - loss: 0.0781 - val_accuracy: 0.8272 - val_loss: 0.3060\n",
            "Epoch 15/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9674 - loss: 0.0830 - val_accuracy: 0.9198 - val_loss: 0.2288\n",
            "Epoch 16/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9690 - loss: 0.0851 - val_accuracy: 0.9383 - val_loss: 0.1621\n",
            "Epoch 17/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9655 - loss: 0.0821 - val_accuracy: 0.9630 - val_loss: 0.1421\n",
            "Epoch 18/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9790 - loss: 0.0541 - val_accuracy: 0.9444 - val_loss: 0.1398\n",
            "Epoch 19/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9754 - loss: 0.0781 - val_accuracy: 0.9198 - val_loss: 0.1880\n",
            "Epoch 20/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9666 - loss: 0.0880 - val_accuracy: 0.9198 - val_loss: 0.2657\n",
            "Epoch 21/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9752 - loss: 0.0738 - val_accuracy: 0.9321 - val_loss: 0.1700\n",
            "Epoch 22/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9824 - loss: 0.0495 - val_accuracy: 0.9321 - val_loss: 0.1720\n",
            "Epoch 23/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9847 - loss: 0.0495 - val_accuracy: 0.9753 - val_loss: 0.0839\n",
            "Epoch 24/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9849 - loss: 0.0686 - val_accuracy: 0.9444 - val_loss: 0.1095\n",
            "Epoch 25/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9779 - loss: 0.0461 - val_accuracy: 0.9691 - val_loss: 0.0853\n",
            "Epoch 26/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9881 - loss: 0.0386 - val_accuracy: 0.7469 - val_loss: 0.6812\n",
            "Epoch 27/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9905 - loss: 0.0384 - val_accuracy: 0.8765 - val_loss: 0.2470\n",
            "Epoch 28/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9906 - loss: 0.0398 - val_accuracy: 0.9444 - val_loss: 0.1386\n",
            "Epoch 29/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9614 - loss: 0.1047 - val_accuracy: 0.7531 - val_loss: 0.5452\n",
            "Epoch 30/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9727 - loss: 0.0693 - val_accuracy: 0.9444 - val_loss: 0.1885\n",
            "Epoch 31/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9870 - loss: 0.0447 - val_accuracy: 0.8827 - val_loss: 0.5599\n",
            "Epoch 32/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9853 - loss: 0.0342 - val_accuracy: 0.9568 - val_loss: 0.1478\n",
            "Epoch 33/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9824 - loss: 0.0403 - val_accuracy: 0.9383 - val_loss: 0.2257\n",
            "Epoch 34/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9844 - loss: 0.0399 - val_accuracy: 0.9568 - val_loss: 0.1124\n",
            "Epoch 35/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9879 - loss: 0.0396 - val_accuracy: 0.9321 - val_loss: 0.3736\n",
            "Epoch 36/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9727 - loss: 0.0592 - val_accuracy: 0.5494 - val_loss: 2.3859\n",
            "Epoch 37/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9525 - loss: 0.1521 - val_accuracy: 0.6605 - val_loss: 1.0202\n",
            "Epoch 38/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9874 - loss: 0.0402 - val_accuracy: 0.8333 - val_loss: 0.5317\n",
            "Epoch 39/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9811 - loss: 0.0504 - val_accuracy: 0.7716 - val_loss: 0.6613\n",
            "Epoch 40/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9785 - loss: 0.0596 - val_accuracy: 0.6667 - val_loss: 1.1893\n",
            "Epoch 41/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9915 - loss: 0.0334 - val_accuracy: 0.9012 - val_loss: 0.2251\n",
            "Epoch 42/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9839 - loss: 0.0478 - val_accuracy: 0.8333 - val_loss: 0.2932\n",
            "Epoch 43/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9905 - loss: 0.0394 - val_accuracy: 0.9444 - val_loss: 0.2245\n",
            "Epoch 44/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9756 - loss: 0.0653 - val_accuracy: 0.9753 - val_loss: 0.0969\n",
            "Epoch 45/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9941 - loss: 0.0186 - val_accuracy: 0.9568 - val_loss: 0.1127\n",
            "Epoch 46/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9892 - loss: 0.0417 - val_accuracy: 0.9136 - val_loss: 0.4157\n",
            "Epoch 47/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9864 - loss: 0.0339 - val_accuracy: 0.9568 - val_loss: 0.1083\n",
            "Epoch 48/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9791 - loss: 0.0608 - val_accuracy: 0.9753 - val_loss: 0.0873\n",
            "Epoch 49/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9794 - loss: 0.0584 - val_accuracy: 0.9568 - val_loss: 0.1040\n",
            "Epoch 50/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9739 - loss: 0.0640 - val_accuracy: 0.9630 - val_loss: 0.1117\n",
            "Test Accuracy: 0.9630\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          AI       0.95      0.98      0.97        86\n",
            "       HUMAN       0.97      0.95      0.96        76\n",
            "\n",
            "    accuracy                           0.96       162\n",
            "   macro avg       0.96      0.96      0.96       162\n",
            "weighted avg       0.96      0.96      0.96       162\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report\n",
        "import pickle\n",
        "\n",
        "file_path = \"/content/tam_training_data_hum_ai (1).csv\"\n",
        "dataset_df = pd.read_csv(file_path)\n",
        "dataset_df.columns = ['id', 'transcript', 'class_label']\n",
        "print(dataset_df.head())\n",
        "\n",
        "stopwords = list(sorted(adv.stopwords['tamil']))\n",
        "\n",
        "def preprocess_tamil_text(text):\n",
        "    \"\"\"Preprocess Tamil text by normalizing, tokenizing, and removing stopwords.\"\"\"\n",
        "    normalizer_factory = IndicNormalizerFactory()\n",
        "    normalizer = normalizer_factory.get_normalizer(\"ta\")\n",
        "    text = normalizer.normalize(text)\n",
        "    tokens = list(indic_tokenize.trivial_tokenize(text, lang=\"ta\"))\n",
        "    tokens = [token for token in tokens if token not in stopwords]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "dataset_df['cleaned_transcript'] = dataset_df['transcript'].apply(preprocess_tamil_text)\n",
        "print(dataset_df.head())\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "dataset_df['encoded_label'] = label_encoder.fit_transform(dataset_df['class_label'])\n",
        "\n",
        "label_encoder_path = \"tamil_label_encoder.pkl\"\n",
        "with open(label_encoder_path, \"wb\") as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "print(f\"Label encoder saved to {label_encoder_path}\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    dataset_df['cleaned_transcript'], dataset_df['encoded_label'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "model_name = \"xlm-roberta-large\"  \n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_texts(texts, tokenizer, max_length=512):\n",
        "    inputs = tokenizer(\n",
        "        texts.tolist(),\n",
        "        max_length=max_length,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    return inputs\n",
        "\n",
        "X_train_tokens = tokenize_texts(X_train, tokenizer)\n",
        "X_test_tokens = tokenize_texts(X_test, tokenizer)\n",
        "\n",
        "def extract_embeddings(tokens, model):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**tokens)\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1).numpy()  \n",
        "    return embeddings\n",
        "\n",
        "X_train_embeddings = extract_embeddings(X_train_tokens, model)\n",
        "X_test_embeddings = extract_embeddings(X_test_tokens, model)\n",
        "\n",
        "def build_model(input_dim, output_dim):\n",
        "    model = Sequential([\n",
        "        Dense(256, input_dim=input_dim, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(output_dim, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "\n",
        "print(\"Training with XLM-Roberta embeddings...\")\n",
        "classification_model = build_model(X_train_embeddings.shape[1], len(label_encoder.classes_))\n",
        "history = classification_model.fit(\n",
        "    X_train_embeddings, y_train_cat,\n",
        "    validation_data=(X_test_embeddings, y_test_cat),\n",
        "    epochs=50, batch_size=32, verbose=1\n",
        ")\n",
        "\n",
        "loss, accuracy = classification_model.evaluate(X_test_embeddings, y_test_cat, verbose=0)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "y_pred = classification_model.predict(X_test_embeddings)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_labels, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiSU-5gfPaRq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00c6ff15e25d402cb2e816b1c896b899": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "073bc76663be415897f87a57bc290cb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fff8f44d8ea461693c2291ca4f1a1b4",
            "placeholder": "​",
            "style": "IPY_MODEL_712e6167d98348bb81e37899d0f28a29",
            "value": " 9.10M/9.10M [00:00&lt;00:00, 30.2MB/s]"
          }
        },
        "090d344035fa43a6815a88e6a2763548": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a8a93826734490b8a8393bc16510bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2331ae681d2420e973c6daa38bc2491",
            "placeholder": "​",
            "style": "IPY_MODEL_cf47ff2517044e04b5b6ce380bb9459d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "17c343faf3b241ca91175991bc4042be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ed20a84879846cda13f547bb2bd2e10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35024dccd6bc43ee9bd336654ccab10c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a3533706dcb46409bf0655c6042846d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3afd9818a1cc457da76571e36c8cf8d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d8bc55b93534deab6081b5c6f376d2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3eee6a60fa634d699e11e7b58418a7dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "417f879758cc4b6db7200b0e3dfdf3d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bbe21d028df41f68883c65fc2377f85",
            "max": 9096718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17c343faf3b241ca91175991bc4042be",
            "value": 9096718
          }
        },
        "4246c2b8d1994ebfa538da0451818b5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4609e512116045c9a6326c2c8ad277d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fd88c3170d44b8e88735be041903f2c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fff8f44d8ea461693c2291ca4f1a1b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6101199d94e9480cadfc0d974b1a555f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61c4ee9e7cec4832b32010dba2cb0a66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98eefd2bb9344c41a915a5b5b4245e98",
            "placeholder": "​",
            "style": "IPY_MODEL_adcadc537d75422bad3fa4657d65973e",
            "value": "tokenizer.json: 100%"
          }
        },
        "695b4f0d29d743e399505fe9a325d736": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d53cd512d2c49d5946b8008518d74e6",
            "placeholder": "​",
            "style": "IPY_MODEL_b95501bae8cc49d5b7f2a75241c635f0",
            "value": " 616/616 [00:00&lt;00:00, 14.2kB/s]"
          }
        },
        "6dda9e7810514db88cf95683b1d13e3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "712e6167d98348bb81e37899d0f28a29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74dfb116fb10461e9365f3eeba58c1c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7631b3c700664994b476a3db28ad1927": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5f4f732d2f243c6b3495cd5bdc36d43",
            "placeholder": "​",
            "style": "IPY_MODEL_3eee6a60fa634d699e11e7b58418a7dd",
            "value": "config.json: 100%"
          }
        },
        "8cddc084eab64e7d8bbd8561aa235ee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d04754271eae4e1680547b73363095c9",
            "max": 616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4246c2b8d1994ebfa538da0451818b5c",
            "value": 616
          }
        },
        "98eefd2bb9344c41a915a5b5b4245e98": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bbe21d028df41f68883c65fc2377f85": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d53cd512d2c49d5946b8008518d74e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ee8c0e3114f4f8cbe3bb51d968d4f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8364238314c446b8841209ac27d8b30",
              "IPY_MODEL_f5c661a8805a4ccd8f4acb5a914c02c0",
              "IPY_MODEL_ec330c0bb88c410f8eec9ddc24c2291e"
            ],
            "layout": "IPY_MODEL_f3b5c16a03514d2d9a8a938ab03d0a9d"
          }
        },
        "a330ab2d45c547f6afef386bef71aa7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5585b75eb31446cb9ce698cacd86183": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5f4f732d2f243c6b3495cd5bdc36d43": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a74b430a2c944e71964c36acd30d722f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adcadc537d75422bad3fa4657d65973e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0409e6fa86f4514b9b610438e4ef36d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fd88c3170d44b8e88735be041903f2c",
            "placeholder": "​",
            "style": "IPY_MODEL_a5585b75eb31446cb9ce698cacd86183",
            "value": " 25.0/25.0 [00:00&lt;00:00, 363B/s]"
          }
        },
        "b1bd168ee8324c04894216dea21fe1d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2331ae681d2420e973c6daa38bc2491": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b250f3f51212410f89d8bf023b461268": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df1bcd3e52094587a9c46ade04df65da",
              "IPY_MODEL_f58a381662e54ab39f50056efd31f9ba",
              "IPY_MODEL_f13911ea7ccf4ef1b24917e1a0bae1c4"
            ],
            "layout": "IPY_MODEL_74dfb116fb10461e9365f3eeba58c1c6"
          }
        },
        "b95501bae8cc49d5b7f2a75241c635f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8c4ca9a78204677a16808acb8510e80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35024dccd6bc43ee9bd336654ccab10c",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a330ab2d45c547f6afef386bef71aa7f",
            "value": 25
          }
        },
        "cf47ff2517044e04b5b6ce380bb9459d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf73d17d7c4a4bdd9a757f39a9dd2021": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a8a93826734490b8a8393bc16510bce",
              "IPY_MODEL_c8c4ca9a78204677a16808acb8510e80",
              "IPY_MODEL_b0409e6fa86f4514b9b610438e4ef36d"
            ],
            "layout": "IPY_MODEL_d0e83ea91a784e56977896cd6d5eebd2"
          }
        },
        "d04754271eae4e1680547b73363095c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d06cd82eb1b74bab8fb12e0e85117d78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_61c4ee9e7cec4832b32010dba2cb0a66",
              "IPY_MODEL_417f879758cc4b6db7200b0e3dfdf3d3",
              "IPY_MODEL_073bc76663be415897f87a57bc290cb9"
            ],
            "layout": "IPY_MODEL_6dda9e7810514db88cf95683b1d13e3e"
          }
        },
        "d0e83ea91a784e56977896cd6d5eebd2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d672faf7d90f4ac3908de5339aae75c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df1bcd3e52094587a9c46ade04df65da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f93a656c6fce480480e65df7910f28e1",
            "placeholder": "​",
            "style": "IPY_MODEL_d672faf7d90f4ac3908de5339aae75c0",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "e0de30e4aea44cc4a6a56b13d41d1990": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8364238314c446b8841209ac27d8b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1bd168ee8324c04894216dea21fe1d9",
            "placeholder": "​",
            "style": "IPY_MODEL_00c6ff15e25d402cb2e816b1c896b899",
            "value": "model.safetensors: 100%"
          }
        },
        "ec330c0bb88c410f8eec9ddc24c2291e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a3533706dcb46409bf0655c6042846d",
            "placeholder": "​",
            "style": "IPY_MODEL_e0de30e4aea44cc4a6a56b13d41d1990",
            "value": " 2.24G/2.24G [00:26&lt;00:00, 85.5MB/s]"
          }
        },
        "f08c792b038445a09da64f7403693a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7631b3c700664994b476a3db28ad1927",
              "IPY_MODEL_8cddc084eab64e7d8bbd8561aa235ee8",
              "IPY_MODEL_695b4f0d29d743e399505fe9a325d736"
            ],
            "layout": "IPY_MODEL_6101199d94e9480cadfc0d974b1a555f"
          }
        },
        "f13911ea7ccf4ef1b24917e1a0bae1c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4609e512116045c9a6326c2c8ad277d2",
            "placeholder": "​",
            "style": "IPY_MODEL_3afd9818a1cc457da76571e36c8cf8d4",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 16.0MB/s]"
          }
        },
        "f3b5c16a03514d2d9a8a938ab03d0a9d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f58a381662e54ab39f50056efd31f9ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d8bc55b93534deab6081b5c6f376d2b",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ed20a84879846cda13f547bb2bd2e10",
            "value": 5069051
          }
        },
        "f5c661a8805a4ccd8f4acb5a914c02c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a74b430a2c944e71964c36acd30d722f",
            "max": 2244817354,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_090d344035fa43a6815a88e6a2763548",
            "value": 2244817354
          }
        },
        "f93a656c6fce480480e65df7910f28e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
